{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59584eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-11-17 00:02:19.144123005 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card1/device/vendor\"\u001b[m\n",
      "/home/pi5/TrafficSign/venv_tsr/lib/python3.13/site-packages/openvino/runtime/__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import onnxruntime as ort\n",
    "from openvino.runtime import Core\n",
    "import ncnn\n",
    "import time\n",
    "import random\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad05458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114)):\n",
    "    \"\"\"Resize and pad image to new_shape with letterbox\"\"\"\n",
    "    shape = img.shape[:2]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "    \n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]\n",
    "    \n",
    "    dw /= 2\n",
    "    dh /= 2\n",
    "    \n",
    "    if shape[::-1] != new_unpad:\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    \n",
    "    return img, r, (dw, dh)\n",
    "\n",
    "\n",
    "def nms_numpy(boxes, scores, iou_threshold=0.45):\n",
    "    \"\"\"Non-Maximum Suppression - DÃ™NG CHUNG CHO Táº¤T Cáº¢\"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    x1, y1, x2, y2 = boxes.T\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        \n",
    "        if len(order) == 1:\n",
    "            break\n",
    "            \n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1)\n",
    "        h = np.maximum(0.0, yy2 - yy1)\n",
    "        inter = w * h\n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-6)\n",
    "\n",
    "        inds = np.where(iou <= iou_threshold)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "def preprocess_image(img, input_size=(640, 640)):\n",
    "    \"\"\"\n",
    "    Preprocess CHUNG cho ONNX/OpenVINO/NCNN (numpy version)\n",
    "    Tráº£ vá» numpy array Ä‘á»ƒ fair\n",
    "    \"\"\"\n",
    "    img_resized, ratio, (dw, dh) = letterbox(img, new_shape=input_size)\n",
    "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "    img_normalized = img_rgb.astype(np.float32) / 255.0\n",
    "    img_transposed = img_normalized.transpose(2, 0, 1)\n",
    "    img_batch = np.expand_dims(img_transposed, axis=0)\n",
    "    \n",
    "    return img_batch, ratio, (dw, dh)\n",
    "\n",
    "\n",
    "def postprocess_with_nms(output, orig_shape, ratio, pad, conf_threshold=0.25, iou_threshold=0.45):\n",
    "    \"\"\"\n",
    "    Postprocess CHUNG CHO Táº¤T Cáº¢ BACKEND (cÃ³ NMS)\n",
    "    Äáº£m báº£o tÃ­nh cÃ´ng báº±ng\n",
    "    \"\"\"\n",
    "    # Normalize shape to (1, 84, 8400)\n",
    "    if isinstance(output, ncnn.Mat):\n",
    "        output = np.array(output)\n",
    "    \n",
    "    if output.ndim == 2:\n",
    "        output = np.expand_dims(output, axis=0)\n",
    "    if output.shape[-1] == 84:\n",
    "        output = output.transpose(0, 2, 1)\n",
    "    \n",
    "    predictions = output[0]  # (84, 8400)\n",
    "    boxes = predictions[:4].T  # (8400, 4)\n",
    "    scores = predictions[4:].T  # (8400, num_classes)\n",
    "    \n",
    "    # Get max score and class\n",
    "    class_scores = np.max(scores, axis=1)\n",
    "    class_ids = np.argmax(scores, axis=1)\n",
    "    \n",
    "    # Filter by confidence\n",
    "    mask = class_scores > conf_threshold\n",
    "    boxes = boxes[mask]\n",
    "    scores = class_scores[mask]\n",
    "    class_ids = class_ids[mask]\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        return np.empty((0, 4)), np.empty((0,)), np.empty((0,))\n",
    "    \n",
    "    # Convert xywh to xyxy\n",
    "    x_center, y_center, width, height = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
    "    x1 = x_center - width / 2\n",
    "    y1 = y_center - height / 2\n",
    "    x2 = x_center + width / 2\n",
    "    y2 = y_center + height / 2\n",
    "    boxes_xyxy = np.stack([x1, y1, x2, y2], axis=1)\n",
    "    \n",
    "    # Scale back to original image\n",
    "    boxes_xyxy[:, [0, 2]] -= pad[0]\n",
    "    boxes_xyxy[:, [1, 3]] -= pad[1]\n",
    "    boxes_xyxy /= ratio\n",
    "    \n",
    "    # Clip to image boundaries\n",
    "    boxes_xyxy[:, [0, 2]] = np.clip(boxes_xyxy[:, [0, 2]], 0, orig_shape[1])\n",
    "    boxes_xyxy[:, [1, 3]] = np.clip(boxes_xyxy[:, [1, 3]], 0, orig_shape[0])\n",
    "    \n",
    "    # Apply NMS per class\n",
    "    nms_indices = []\n",
    "    for cls in np.unique(class_ids):\n",
    "        cls_mask = class_ids == cls\n",
    "        keep = nms_numpy(boxes_xyxy[cls_mask], scores[cls_mask], iou_threshold)\n",
    "        nms_indices.extend(np.where(cls_mask)[0][keep])\n",
    "    \n",
    "    if len(nms_indices) > 0:\n",
    "        nms_indices = np.array(nms_indices)\n",
    "        boxes_xyxy = boxes_xyxy[nms_indices]\n",
    "        scores = scores[nms_indices]\n",
    "        class_ids = class_ids[nms_indices]\n",
    "    else:\n",
    "        boxes_xyxy = np.empty((0, 4))\n",
    "        scores = np.empty((0,))\n",
    "        class_ids = np.empty((0,))\n",
    "    \n",
    "    return boxes_xyxy, scores, class_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb5b5f",
   "metadata": {},
   "source": [
    "# EVAL PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a1736a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffe8bbbc190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a5d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_pytorch_inference(\n",
    "    model_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    iou_threshold=0.45,\n",
    "    device='cpu'\n",
    "):\n",
    "    \n",
    "    \"\"\"Benchmark PyTorch model vá»›i cÃ¹ng preprocessing/postprocessing\"\"\"\n",
    "    print(f\"\\nğŸš€ Benchmarking PyTorch: {Path(model_path).name}\")\n",
    "    print(f\"ğŸ“ Input size: {input_size}\")\n",
    "    print(f\"ğŸ–¥ï¸  Device: {device}\")\n",
    "    print(f\"ğŸ“Š Running {num_samples} samples (after {num_warmup} warmup)\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    model = YOLO(model_path)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_config.get('val', 'valid/images')\n",
    "    image_files = list(val_path.glob('*.jpg')) + list(val_path.glob('*.png'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "        \n",
    "    # Warmup\n",
    "    print(f\"ğŸ”¥ Warmup ({num_warmup} runs)...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        input_tensor, _, _ = preprocess_image(img, input_size=input_size)\n",
    "        input_torch = torch.from_numpy(input_tensor).to(device)\n",
    "        with torch.no_grad():\n",
    "            _ = model.model(input_torch)\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Running inference on {len(sample_images)} test images...\")\n",
    "    for img_path in sample_images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        input_tensor, ratio, pad = preprocess_image(img, input_size=input_size)\n",
    "        input_torch = torch.from_numpy(input_tensor).to(device)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model.model(input_torch)\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # Postprocess\n",
    "        output_np = outputs[0].cpu().numpy() if isinstance(outputs[0], torch.Tensor) else outputs[0]\n",
    "        boxes, scores, class_ids = postprocess_with_nms(\n",
    "            output_np, (orig_h, orig_w), ratio, pad, conf_threshold, iou_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   ğŸ§© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   âš™ï¸  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   ğŸ“¦ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   â±ï¸  Total: {total_ms:.2f} ms â†’ {fps:.2f} FPS\")\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": f\"PyTorch ({device.upper()})\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f2fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_onnx_inference(\n",
    "    onnx_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    iou_threshold=0.45,\n",
    "    device_provider='CPUExecutionProvider'\n",
    "):\n",
    "    \"\"\"Benchmark ONNX vá»›i postprocess GIá»NG Há»†T cÃ¡c backend khÃ¡c\"\"\"\n",
    "    print(f\"\\nğŸš€ Benchmarking ONNX: {Path(onnx_path).name}\")\n",
    "    print(f\"âš™ï¸  Provider: {device_provider}\")\n",
    "    print(f\"ğŸ“ Input size: {input_size}\")\n",
    "    print(f\"ğŸ“Š Running {num_samples} images (after {num_warmup} warmup)\")\n",
    "    \n",
    "    # Load model\n",
    "    session = ort.InferenceSession(onnx_path, providers=[device_provider])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_config.get('val', 'valid/images')\n",
    "    image_files = list(val_path.glob('*.jpg')) + list(val_path.glob('*.png'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    # Warmup\n",
    "    print(f\"\\nğŸ”¥ Warmup ({num_warmup} runs)...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        input_tensor, _, _ = preprocess_image(img, input_size=input_size)\n",
    "        _ = session.run(None, {input_name: input_tensor})\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Running inference on {len(sample_images)} test images...\")\n",
    "    for img_path in sample_images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        input_tensor, ratio, pad = preprocess_image(img, input_size=input_size)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        outputs = session.run(None, {input_name: input_tensor})\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # Postprocess (DÃ™NG HÃ€M CHUNG)\n",
    "        boxes, scores, class_ids = postprocess_with_nms(\n",
    "            outputs[0], (orig_h, orig_w), ratio, pad, conf_threshold, iou_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   ğŸ§© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   âš™ï¸  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   ğŸ“¦ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   â±ï¸  Total: {total_ms:.2f} ms â†’ {fps:.2f} FPS\")\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": \"ONNX (CPU)\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476fe696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_openvino_inference(\n",
    "    model_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    iou_threshold=0.45,\n",
    "    device=\"CPU\"\n",
    "):\n",
    "    \"\"\"Benchmark OpenVINO vá»›i postprocess GIá»NG Há»†T cÃ¡c backend khÃ¡c\"\"\"\n",
    "    print(f\"\\nğŸš€ Benchmarking OpenVINO: {Path(model_path).name}\")\n",
    "    print(f\"ğŸ“ Input size: {input_size}\")\n",
    "    print(f\"ğŸ–¥ï¸  Device: {device}\")\n",
    "    print(f\"ğŸ“Š Running {num_samples} samples (after {num_warmup} warmup)\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    ie = Core()\n",
    "    model = ie.read_model(model=model_path)\n",
    "    compiled_model = ie.compile_model(model=model, device_name=device)\n",
    "    input_layer = compiled_model.input(0)\n",
    "    output_layer = compiled_model.output(0)\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_cfg = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_cfg.get(\"val\", \"valid/images\")\n",
    "    image_files = list(val_path.glob(\"*.jpg\")) + list(val_path.glob(\"*.png\"))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    # Warmup\n",
    "    print(f\"ğŸ”¥ Warming up for {num_warmup} runs...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        input_tensor, _, _ = preprocess_image(img, input_size=input_size)\n",
    "        _ = compiled_model([input_tensor])[output_layer]\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Running timed inference on {len(sample_images)} test images...\")\n",
    "    for img_path in sample_images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        input_tensor, ratio, pad = preprocess_image(img, input_size=input_size)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        outputs = compiled_model([input_tensor])[output_layer]\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # Postprocess (DÃ™NG HÃ€M CHUNG)\n",
    "        boxes, scores, class_ids = postprocess_with_nms(\n",
    "            outputs, (orig_h, orig_w), ratio, pad, conf_threshold, iou_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   ğŸ§© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   âš™ï¸  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   ğŸ“¦ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   â±ï¸  Total: {total_ms:.2f} ms â†’ {fps:.2f} FPS\")\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": \"OpenVINO (CPU)\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1da44eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_ncnn(img, input_size=(640, 640)):\n",
    "    \"\"\"\n",
    "    Preprocess cho NCNN - convert sang ncnn.Mat tá»« numpy array\n",
    "    Äá»ƒ fair, ta váº«n dÃ¹ng letterbox giá»‘ng cÃ¡c backend khÃ¡c\n",
    "    \"\"\"\n",
    "    # DÃ¹ng letterbox chung\n",
    "    img_resized, ratio, (dw, dh) = letterbox(img, new_shape=input_size)\n",
    "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to ncnn.Mat\n",
    "    mat_in = ncnn.Mat.from_pixels(\n",
    "        img_rgb,\n",
    "        ncnn.Mat.PixelType.PIXEL_RGB,\n",
    "        img_rgb.shape[1],\n",
    "        img_rgb.shape[0]\n",
    "    )\n",
    "    \n",
    "    # Normalize\n",
    "    mean_vals = [0, 0, 0]\n",
    "    norm_vals = [1/255.0, 1/255.0, 1/255.0]\n",
    "    mat_in.substract_mean_normalize(mean_vals, norm_vals)\n",
    "    \n",
    "    return mat_in, ratio, (dw, dh)\n",
    "\n",
    "\n",
    "def benchmark_ncnn_inference(\n",
    "    param_path,\n",
    "    bin_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    iou_threshold=0.45,\n",
    "    input_name=\"in0\",\n",
    "    output_name=\"out0\",\n",
    "    use_gpu=False,\n",
    "    num_threads=4,\n",
    "):\n",
    "    \"\"\"Benchmark NCNN vá»›i postprocess GIá»NG Há»†T cÃ¡c backend khÃ¡c\"\"\"\n",
    "    print(f\"\\nğŸš€ Benchmarking NCNN: {Path(param_path).stem}\")\n",
    "    print(f\"ğŸ“¦ Model: {param_path}\")\n",
    "    print(f\"ğŸ§© Device: {'GPU (Vulkan)' if use_gpu else f'CPU ({num_threads} threads)'}\")\n",
    "    print(f\"ğŸ“ Input size: {input_size}\")\n",
    "    print(f\"ğŸ“Š Running {num_samples} images (after {num_warmup} warmup)\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    net = ncnn.Net()\n",
    "    net.opt.use_vulkan_compute = use_gpu\n",
    "    net.opt.num_threads = num_threads\n",
    "    \n",
    "    if net.load_param(param_path) != 0:\n",
    "        raise RuntimeError(f\"Failed to load param: {param_path}\")\n",
    "    if net.load_model(bin_path) != 0:\n",
    "        raise RuntimeError(f\"Failed to load bin: {bin_path}\")\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_config.get('val', 'valid/images')\n",
    "    image_files = list(val_path.glob('*.jpg')) + list(val_path.glob('*.png'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    # Warmup\n",
    "    print(f\"ğŸ”¥ Warmup ({num_warmup} runs)...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        mat_in, _, _ = preprocess_image_ncnn(img, input_size=input_size)\n",
    "        ex = net.create_extractor()\n",
    "        ex.input(input_name, mat_in)\n",
    "        ex.extract(output_name)\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Running inference on {len(sample_images)} test images...\")\n",
    "    for img_path in sample_images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        mat_in, ratio, pad = preprocess_image_ncnn(img, input_size=input_size)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        ex = net.create_extractor()\n",
    "        ex.input(input_name, mat_in)\n",
    "        ret, mat_out = ex.extract(output_name)\n",
    "        t2 = time.time()\n",
    "        \n",
    "        if ret != 0:\n",
    "            print(f\"âš ï¸  Failed inference on {img_path.name}\")\n",
    "            continue\n",
    "        \n",
    "        # Postprocess (DÃ™NG HÃ€M CHUNG)\n",
    "        output_array = np.array(mat_out)\n",
    "        boxes, scores, class_ids = postprocess_with_nms(\n",
    "            output_array, (orig_h, orig_w), ratio, pad, conf_threshold, iou_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   ğŸ§© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   âš™ï¸  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   ğŸ“¦ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   â±ï¸  Total: {total_ms:.2f} ms â†’ {fps:.2f} FPS\\n\")\n",
    "    \n",
    "    device_name = \"GPU (Vulkan)\" if use_gpu else f\"CPU ({num_threads}t)\"\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": f\"NCNN ({device_name})\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64d0f8",
   "metadata": {},
   "source": [
    "### RUN EVAL FPS PYTORCH ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f822c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ”¥ PYTORCH BENCHMARK\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Benchmarking PyTorch: yolo5.pt\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: cpu\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 5.31 ms\n",
      "   âš™ï¸  Inference : 396.28 ms\n",
      "   ğŸ“¦ Postprocess: 0.47 ms\n",
      "   â±ï¸  Total: 402.05 ms â†’ 2.49 FPS\n",
      "\n",
      "ğŸš€ Benchmarking PyTorch: yolo8.pt\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: cpu\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 5.14 ms\n",
      "   âš™ï¸  Inference : 422.35 ms\n",
      "   ğŸ“¦ Postprocess: 0.47 ms\n",
      "   â±ï¸  Total: 427.96 ms â†’ 2.34 FPS\n",
      "\n",
      "ğŸš€ Benchmarking PyTorch: yolo11.pt\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: cpu\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 5.18 ms\n",
      "   âš™ï¸  Inference : 397.87 ms\n",
      "   ğŸ“¦ Postprocess: 0.47 ms\n",
      "   â±ï¸  Total: 403.52 ms â†’ 2.48 FPS\n",
      "\n",
      "ğŸš€ Benchmarking PyTorch: yolo_plus_v2.pt\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: cpu\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 5.25 ms\n",
      "   âš™ï¸  Inference : 195.03 ms\n",
      "   ğŸ“¦ Postprocess: 0.45 ms\n",
      "   â±ï¸  Total: 200.74 ms â†’ 4.98 FPS\n",
      "\n",
      "============================================================\n",
      "ğŸ”¥ ONNX BENCHMARK\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Benchmarking ONNX: yolo5.onnx\n",
      "âš™ï¸  Provider: CPUExecutionProvider\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 5.03 ms\n",
      "   âš™ï¸  Inference : 130.59 ms\n",
      "   ğŸ“¦ Postprocess: 0.46 ms\n",
      "   â±ï¸  Total: 136.08 ms â†’ 7.35 FPS\n",
      "\n",
      "ğŸš€ Benchmarking ONNX: yolo8.onnx\n",
      "âš™ï¸  Provider: CPUExecutionProvider\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 4.88 ms\n",
      "   âš™ï¸  Inference : 140.56 ms\n",
      "   ğŸ“¦ Postprocess: 0.46 ms\n",
      "   â±ï¸  Total: 145.90 ms â†’ 6.85 FPS\n",
      "\n",
      "ğŸš€ Benchmarking ONNX: yolo11.onnx\n",
      "âš™ï¸  Provider: CPUExecutionProvider\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 4.87 ms\n",
      "   âš™ï¸  Inference : 140.78 ms\n",
      "   ğŸ“¦ Postprocess: 0.46 ms\n",
      "   â±ï¸  Total: 146.12 ms â†’ 6.84 FPS\n",
      "\n",
      "ğŸš€ Benchmarking ONNX: yolo_plus.onnx\n",
      "âš™ï¸  Provider: CPUExecutionProvider\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 4.89 ms\n",
      "   âš™ï¸  Inference : 64.59 ms\n",
      "   ğŸ“¦ Postprocess: 0.46 ms\n",
      "   â±ï¸  Total: 69.94 ms â†’ 14.30 FPS\n",
      "\n",
      "============================================================\n",
      "âœ… BENCHMARK SUMMARY\n",
      "============================================================\n",
      "      Model       Backend  Avg Preprocess (ms)  Avg Inference (ms)  Avg Postprocess (ms)  Total (ms)       FPS\n",
      "    YOLOv5n PyTorch (CPU)             5.309286          396.276259              0.469379  402.054925  2.487222\n",
      "    YOLOv8n PyTorch (CPU)             5.138588          422.350142              0.467515  427.956245  2.336687\n",
      "    YOLO11n PyTorch (CPU)             5.179040          397.869024              0.473921  403.521986  2.478180\n",
      "yolo_custom PyTorch (CPU)             5.254102          195.034440              0.453813  200.742354  4.981510\n",
      "    YOLOv5n    ONNX (CPU)             5.032322          130.590343              0.455053  136.077719  7.348742\n",
      "    YOLOv8n    ONNX (CPU)             4.882321          140.559599              0.461967  145.903888  6.853827\n",
      "    YOLO11n    ONNX (CPU)             4.873281          140.779366              0.463507  146.116154  6.843870\n",
      "yolo_custom    ONNX (CPU)             4.890287           64.590101              0.456564   69.936953 14.298593\n",
      "\n",
      "ğŸ’¾ Saved results to: ./Eval/FPS/detect_eval_results_fps_v5_8_11_custom.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataset path\n",
    "data_yaml = \"./Dataset/Detect/data_detect_vntsr/data.yaml\"\n",
    "\n",
    "# Model paths\n",
    "models_pt = {\n",
    "    \"YOLOv5n\": \"./weight/yolo5.pt\",\n",
    "    \"YOLOv8n\": \"./weight/yolo8.pt\",\n",
    "    \"YOLO11n\": \"./weight/yolo11.pt\",\n",
    "    \"yolo_custom\": \"./weight/yolo_plus/yolo_plus_v2.pt\",\n",
    "}\n",
    "\n",
    "models_onnx = {\n",
    "    \"YOLOv5n\": \"./convert/model/yolo5/yolo5.onnx\",\n",
    "    \"YOLOv8n\": \"./convert/model/yolo8/yolo8.onnx\",\n",
    "    \"YOLO11n\": \"./convert/model/yolo11/yolo11.onnx\",\n",
    "    \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus.onnx\",\n",
    "\n",
    "}\n",
    "\n",
    "# models_openvino = {\n",
    "#     \"YOLOv5n\": \"./convert/model/yolov5/yolo5_openvino_model/yolo5.xml\",\n",
    "#     \"YOLOv8n\": \"./convert/model/yolov8/yolo8_openvino_model/yolo8.xml\",\n",
    "#     \"YOLO11n\": \"./convert/model/yolov11/yolo11_openvino_model/yolo11.xml\",\n",
    "#     \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus_openvino_model/yolo_plus.xml\",\n",
    "# }\n",
    "\n",
    "# models_ncnn = {\n",
    "#     \"YOLOv5n\": \"./convert/model/yolov5/yolo5_ncnn_model\",\n",
    "#     \"YOLOv8n\": \"./convert/model/yolov8/yolo8_ncnn_model\",\n",
    "#     \"YOLO11n\": \"./convert/model/yolov11/yolo11_ncnn_model\",\n",
    "#     \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus_ncnn_model\",\n",
    "# }\n",
    "\n",
    "results = []\n",
    "\n",
    "# %%\n",
    "# --- Benchmark PyTorch ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¥ PYTORCH BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_path in models_pt.items():\n",
    "    try:\n",
    "        result = benchmark_pytorch_inference(\n",
    "            model_path=model_path,\n",
    "            data_yaml=data_yaml,\n",
    "            model_name=model_name,\n",
    "            input_size=(640, 640),\n",
    "            num_warmup=5,\n",
    "            num_samples=100,\n",
    "            device='cpu'\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error benchmarking PyTorch {model_name}: {e}\")\n",
    "\n",
    "# %%\n",
    "# --- Benchmark ONNX ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¥ ONNX BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_path in models_onnx.items():\n",
    "    try:\n",
    "        result = benchmark_onnx_inference(\n",
    "            onnx_path=model_path,\n",
    "            data_yaml=data_yaml,\n",
    "            model_name=model_name,\n",
    "            input_size=(640, 640),\n",
    "            num_warmup=5,\n",
    "            num_samples=100,\n",
    "            device_provider=\"CPUExecutionProvider\"\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error benchmarking ONNX {model_name}: {e}\")\n",
    "# # --- Benchmark OpenVINO ---\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"ğŸ”¥ OPENVINO BENCHMARK\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# for model_name, model_path in models_openvino.items():\n",
    "#     try:\n",
    "#         result = benchmark_openvino_inference(\n",
    "#             model_path=model_path,\n",
    "#             data_yaml=data_yaml,\n",
    "#             model_name=model_name,\n",
    "#             input_size=(640, 640),\n",
    "#             num_warmup=5,\n",
    "#             num_samples=100,\n",
    "#             device=\"CPU\"\n",
    "#         )\n",
    "#         if result:\n",
    "#             results.append(result)\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ Error benchmarking OpenVINO {model_name}: {e}\")\n",
    "\n",
    "# # %%\n",
    "# # --- Benchmark NCNN ---\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"ğŸ”¥ NCNN BENCHMARK\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# for model_name, model_dir in models_ncnn.items():\n",
    "#     try:\n",
    "#         param_path = os.path.join(model_dir, \"model.ncnn.param\")\n",
    "#         bin_path = os.path.join(model_dir, \"model.ncnn.bin\")\n",
    "        \n",
    "#         if not (os.path.exists(param_path) and os.path.exists(bin_path)):\n",
    "#             print(f\"âš ï¸  Missing NCNN model files for {model_name}, skipping.\")\n",
    "#             continue\n",
    "        \n",
    "#         result = benchmark_ncnn_inference(\n",
    "#             param_path=param_path,\n",
    "#             bin_path=bin_path,\n",
    "#             data_yaml=data_yaml,\n",
    "#             model_name=model_name,\n",
    "#             input_size=(640, 640),\n",
    "#             num_warmup=5,\n",
    "#             num_samples=100,\n",
    "#             use_gpu=False,\n",
    "#             num_threads=4\n",
    "#         )\n",
    "#         if result:\n",
    "#             results.append(result)\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ Error benchmarking NCNN {model_name}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… BENCHMARK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "save_path = \"./Eval/FPS/detect_eval_results_fps_v5_8_11_custom.csv\"\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"\\nğŸ’¾ Saved results to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d184b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ”¥ OPENVINO BENCHMARK\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Benchmarking OpenVINO: yolo5.xml\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: CPU\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warming up for 5 runs...\n",
      "\n",
      "â±ï¸  Running timed inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 4.92 ms\n",
      "   âš™ï¸  Inference : 64.72 ms\n",
      "   ğŸ“¦ Postprocess: 0.46 ms\n",
      "   â±ï¸  Total: 70.11 ms â†’ 14.26 FPS\n",
      "\n",
      "ğŸš€ Benchmarking OpenVINO: yolo8.xml\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: CPU\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warming up for 5 runs...\n",
      "\n",
      "â±ï¸  Running timed inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 4.92 ms\n",
      "   âš™ï¸  Inference : 67.03 ms\n",
      "   ğŸ“¦ Postprocess: 0.47 ms\n",
      "   â±ï¸  Total: 72.42 ms â†’ 13.81 FPS\n",
      "\n",
      "ğŸš€ Benchmarking OpenVINO: yolo11.xml\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: CPU\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warming up for 5 runs...\n",
      "\n",
      "â±ï¸  Running timed inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 4.88 ms\n",
      "   âš™ï¸  Inference : 67.62 ms\n",
      "   ğŸ“¦ Postprocess: 0.46 ms\n",
      "   â±ï¸  Total: 72.96 ms â†’ 13.71 FPS\n",
      "\n",
      "ğŸš€ Benchmarking OpenVINO: yolo_plus.xml\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: CPU\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warming up for 5 runs...\n",
      "\n",
      "â±ï¸  Running timed inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 4.89 ms\n",
      "   âš™ï¸  Inference : 38.65 ms\n",
      "   ğŸ“¦ Postprocess: 0.44 ms\n",
      "   â±ï¸  Total: 43.98 ms â†’ 22.74 FPS\n",
      "\n",
      "============================================================\n",
      "ğŸ”¥ NCNN BENCHMARK\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Benchmarking NCNN: model.ncnn\n",
      "ğŸ“¦ Model: ./convert/model/yolo5/yolo5_ncnn_model/model.ncnn.param\n",
      "ğŸ§© Device: CPU (4 threads)\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 6.31 ms\n",
      "   âš™ï¸  Inference : 65.69 ms\n",
      "   ğŸ“¦ Postprocess: 0.54 ms\n",
      "   â±ï¸  Total: 72.54 ms â†’ 13.78 FPS\n",
      "\n",
      "\n",
      "ğŸš€ Benchmarking NCNN: model.ncnn\n",
      "ğŸ“¦ Model: ./convert/model/yolo8/yolo8_ncnn_model/model.ncnn.param\n",
      "ğŸ§© Device: CPU (4 threads)\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 6.51 ms\n",
      "   âš™ï¸  Inference : 66.44 ms\n",
      "   ğŸ“¦ Postprocess: 0.52 ms\n",
      "   â±ï¸  Total: 73.47 ms â†’ 13.61 FPS\n",
      "\n",
      "\n",
      "ğŸš€ Benchmarking NCNN: model.ncnn\n",
      "ğŸ“¦ Model: ./convert/model/yolo11/yolo11_ncnn_model/model.ncnn.param\n",
      "ğŸ§© Device: CPU (4 threads)\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 6.27 ms\n",
      "   âš™ï¸  Inference : 66.06 ms\n",
      "   ğŸ“¦ Postprocess: 0.53 ms\n",
      "   â±ï¸  Total: 72.87 ms â†’ 13.72 FPS\n",
      "\n",
      "\n",
      "ğŸš€ Benchmarking NCNN: model.ncnn\n",
      "ğŸ“¦ Model: ./convert/model/yolo_plus/yolo_plus_ncnn_model/model.ncnn.param\n",
      "ğŸ§© Device: CPU (4 threads)\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 5.96 ms\n",
      "   âš™ï¸  Inference : 35.11 ms\n",
      "   ğŸ“¦ Postprocess: 0.53 ms\n",
      "   â±ï¸  Total: 41.61 ms â†’ 24.04 FPS\n",
      "\n",
      "\n",
      "============================================================\n",
      "âœ… BENCHMARK SUMMARY\n",
      "============================================================\n",
      "      Model         Backend  Avg Preprocess (ms)  Avg Inference (ms)  Avg Postprocess (ms)  Total (ms)       FPS\n",
      "     YOLO5n  OpenVINO (CPU)             4.923692           64.723167              0.462902   70.109761 14.263349\n",
      "     YOLO8n  OpenVINO (CPU)             4.923713           67.027788              0.465901   72.417402 13.808836\n",
      "    YOLO11n  OpenVINO (CPU)             4.881384           67.619884              0.462985   72.964253 13.705341\n",
      "yolo_custom  OpenVINO (CPU)             4.886699           38.647795              0.441198   43.975692 22.739836\n",
      "     YOLO5n NCNN (CPU (4t))             6.310623           65.691628              0.540836   72.543087 13.784911\n",
      "     YOLO8n NCNN (CPU (4t))             6.510487           66.436872              0.524063   73.471422 13.610734\n",
      "    YOLO11n NCNN (CPU (4t))             6.272714           66.063099              0.533388   72.869201 13.723219\n",
      "yolo_custom NCNN (CPU (4t))             5.963755           35.111947              0.529568   41.605270 24.035417\n",
      "\n",
      "ğŸ’¾ Saved results to: ./Eval/FPS/detect_eval_results_fps_v5_8_11_custom_part2.csv\n"
     ]
    }
   ],
   "source": [
    "models_openvino = {\n",
    "    \"YOLO5n\": \"./convert/model/yolo5/yolo5_openvino_model/yolo5.xml\",\n",
    "    \"YOLO8n\": \"./convert/model/yolo8/yolo8_openvino_model/yolo8.xml\",\n",
    "    \"YOLO11n\": \"./convert/model/yolo11/yolo11_openvino_model/yolo11.xml\",\n",
    "    \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus_openvino_model/yolo_plus.xml\",\n",
    "}\n",
    "\n",
    "models_ncnn = {\n",
    "    \"YOLO5n\": \"./convert/model/yolo5/yolo5_ncnn_model\",\n",
    "    \"YOLO8n\": \"./convert/model/yolo8/yolo8_ncnn_model\",\n",
    "    \"YOLO11n\": \"./convert/model/yolo11/yolo11_ncnn_model\",\n",
    "    \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus_ncnn_model\",\n",
    "}\n",
    "\n",
    "results = []\n",
    "# --- Benchmark OpenVINO ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¥ OPENVINO BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_path in models_openvino.items():\n",
    "    try:\n",
    "        result = benchmark_openvino_inference(\n",
    "            model_path=model_path,\n",
    "            data_yaml=data_yaml,\n",
    "            model_name=model_name,\n",
    "            input_size=(640, 640),\n",
    "            num_warmup=5,\n",
    "            num_samples=100,\n",
    "            device=\"CPU\"\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error benchmarking OpenVINO {model_name}: {e}\")\n",
    "\n",
    "# %%\n",
    "# --- Benchmark NCNN ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¥ NCNN BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_dir in models_ncnn.items():\n",
    "    try:\n",
    "        param_path = os.path.join(model_dir, \"model.ncnn.param\")\n",
    "        bin_path = os.path.join(model_dir, \"model.ncnn.bin\")\n",
    "        \n",
    "        if not (os.path.exists(param_path) and os.path.exists(bin_path)):\n",
    "            print(f\"âš ï¸  Missing NCNN model files for {model_name}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        result = benchmark_ncnn_inference(\n",
    "            param_path=param_path,\n",
    "            bin_path=bin_path,\n",
    "            data_yaml=data_yaml,\n",
    "            model_name=model_name,\n",
    "            input_size=(640, 640),\n",
    "            num_warmup=5,\n",
    "            num_samples=100,\n",
    "            use_gpu=False,\n",
    "            num_threads=4\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error benchmarking NCNN {model_name}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… BENCHMARK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "save_path = \"./Eval/FPS/detect_eval_results_fps_v5_8_11_custom_part2.csv\"\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"\\nğŸ’¾ Saved results to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
