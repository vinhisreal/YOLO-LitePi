{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59535bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, ssd300_vgg16\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47191b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_rcnn_ssd(img, input_size=(640, 640)):\n",
    "    \"\"\"\n",
    "    Preprocess cho Faster R-CNN v√† SSD\n",
    "    Tr·∫£ v·ªÅ tensor ƒë√£ chu·∫©n h√≥a, ratio v√† padding\n",
    "    \"\"\"\n",
    "    orig_h, orig_w = img.shape[:2]\n",
    "    target_h, target_w = input_size\n",
    "    \n",
    "    # T√≠nh ratio ƒë·ªÉ gi·ªØ aspect ratio\n",
    "    ratio = min(target_w / orig_w, target_h / orig_h)\n",
    "    new_w = int(orig_w * ratio)\n",
    "    new_h = int(orig_h * ratio)\n",
    "    \n",
    "    # Resize ·∫£nh\n",
    "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Padding ƒë·ªÉ ƒë·∫°t ƒë√∫ng input_size\n",
    "    pad_w = target_w - new_w\n",
    "    pad_h = target_h - new_h\n",
    "    top = pad_h // 2\n",
    "    bottom = pad_h - top\n",
    "    left = pad_w // 2\n",
    "    right = pad_w - left\n",
    "    \n",
    "    padded = cv2.copyMakeBorder(\n",
    "        resized, top, bottom, left, right, \n",
    "        cv2.BORDER_CONSTANT, value=(114, 114, 114)\n",
    "    )\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(padded, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to tensor v√† normalize [0, 1]\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    img_tensor = transform(Image.fromarray(img_rgb))\n",
    "    \n",
    "    pad = (left, top)\n",
    "    \n",
    "    return img_tensor, ratio, pad\n",
    "\n",
    "\n",
    "def postprocess_rcnn_ssd(predictions, orig_shape, ratio, pad, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Postprocess cho Faster R-CNN v√† SSD\n",
    "    predictions: dict v·ªõi keys 'boxes', 'scores', 'labels'\n",
    "    \"\"\"\n",
    "    boxes = predictions['boxes'].cpu().numpy()\n",
    "    scores = predictions['scores'].cpu().numpy()\n",
    "    labels = predictions['labels'].cpu().numpy()\n",
    "    \n",
    "    # Filter theo confidence threshold\n",
    "    keep = scores >= conf_threshold\n",
    "    boxes = boxes[keep]\n",
    "    scores = scores[keep]\n",
    "    labels = labels[keep]\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        return np.array([]), np.array([]), np.array([])\n",
    "    \n",
    "    # Unpad v√† scale v·ªÅ original size\n",
    "    pad_left, pad_top = pad\n",
    "    orig_h, orig_w = orig_shape\n",
    "    \n",
    "    # Remove padding\n",
    "    boxes[:, [0, 2]] -= pad_left\n",
    "    boxes[:, [1, 3]] -= pad_top\n",
    "    \n",
    "    # Scale v·ªÅ original size\n",
    "    boxes[:, [0, 2]] /= ratio\n",
    "    boxes[:, [1, 3]] /= ratio\n",
    "    \n",
    "    # Clip v·ªÅ image bounds\n",
    "    boxes[:, [0, 2]] = np.clip(boxes[:, [0, 2]], 0, orig_w)\n",
    "    boxes[:, [1, 3]] = np.clip(boxes[:, [1, 3]], 0, orig_h)\n",
    "    \n",
    "    # Convert labels (torchvision: 0=background, 1=traffic_sign)\n",
    "    # Chuy·ªÉn v·ªÅ 0-indexed cho class_ids\n",
    "    class_ids = labels - 1\n",
    "    \n",
    "    return boxes, scores, class_ids\n",
    "\n",
    "\n",
    "def benchmark_faster_rcnn_inference(\n",
    "    model_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    device='cpu'\n",
    "):\n",
    "    \"\"\"Benchmark Faster R-CNN v·ªõi c√πng preprocessing/postprocessing\"\"\"\n",
    "    print(f\"\\nüöÄ Benchmarking Faster R-CNN: {Path(model_path).name}\")\n",
    "    print(f\"üìê Input size: {input_size}\")\n",
    "    print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "    print(f\"üìä Running {num_samples} samples (after {num_warmup} warmup)\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    NUM_CLASSES = 2  # background + traffic_sign\n",
    "    model = fasterrcnn_resnet50_fpn(weights=None)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_config.get('val', 'valid/images')\n",
    "    image_files = list(val_path.glob('*.jpg')) + list(val_path.glob('*.png'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "        \n",
    "    # Warmup\n",
    "    print(f\"üî• Warmup ({num_warmup} runs)...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        input_tensor, _, _ = preprocess_image_rcnn_ssd(img, input_size=input_size)\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        with torch.no_grad():\n",
    "            _ = model([input_tensor])\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Running inference on {len(sample_images)} test images...\")\n",
    "    for img_path in tqdm(sample_images, desc=\"Processing images\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        input_tensor, ratio, pad = preprocess_image_rcnn_ssd(img, input_size=input_size)\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            predictions = model([input_tensor])\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # Postprocess\n",
    "        boxes, scores, class_ids = postprocess_rcnn_ssd(\n",
    "            predictions[0], (orig_h, orig_w), ratio, pad, conf_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nüìä Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   üß© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   ‚öôÔ∏è  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   üì¶ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   ‚è±Ô∏è  Total: {total_ms:.2f} ms ‚Üí {fps:.2f} FPS\")\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": f\"PyTorch Faster-RCNN ({device.upper()})\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930b7050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_ssd300_inference(\n",
    "    model_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    device='cpu'\n",
    "):\n",
    "    \"\"\"Benchmark SSD300 v·ªõi c√πng preprocessing/postprocessing\"\"\"\n",
    "    print(f\"\\nüöÄ Benchmarking SSD300: {Path(model_path).name}\")\n",
    "    print(f\"üìê Input size: {input_size}\")\n",
    "    print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "    print(f\"üìä Running {num_samples} samples (after {num_warmup} warmup)\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    NUM_CLASSES = 2  # background + traffic_sign\n",
    "    model = ssd300_vgg16(weights=None, num_classes=NUM_CLASSES)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_config.get('val', 'valid/images')\n",
    "    image_files = list(val_path.glob('*.jpg')) + list(val_path.glob('*.png'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "        \n",
    "    # Warmup\n",
    "    print(f\"üî• Warmup ({num_warmup} runs)...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        input_tensor, _, _ = preprocess_image_rcnn_ssd(img, input_size=input_size)\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        with torch.no_grad():\n",
    "            _ = model([input_tensor])\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Running inference on {len(sample_images)} test images...\")\n",
    "    for img_path in tqdm(sample_images, desc=\"Processing images\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        input_tensor, ratio, pad = preprocess_image_rcnn_ssd(img, input_size=input_size)\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            predictions = model([input_tensor])\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # Postprocess\n",
    "        boxes, scores, class_ids = postprocess_rcnn_ssd(\n",
    "            predictions[0], (orig_h, orig_w), ratio, pad, conf_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nüìä Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   üß© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   ‚öôÔ∏è  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   üì¶ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   ‚è±Ô∏è  Total: {total_ms:.2f} ms ‚Üí {fps:.2f} FPS\")\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": f\"PyTorch SSD300 ({device.upper()})\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5585bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üî• FASTER R-CNN BENCHMARK\n",
      "============================================================\n",
      "\n",
      "üöÄ Benchmarking Faster R-CNN: faster_rcnn.pth\n",
      "üìê Input size: (640, 640)\n",
      "üñ•Ô∏è  Device: cpu\n",
      "üìä Running 25 samples (after 5 warmup)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Warmup (5 runs)...\n",
      "\n",
      "‚è±Ô∏è  Running inference on 25 test images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [02:22<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Average Timing (over 25 images):\n",
      "   üß© Preprocess: 9.40 ms\n",
      "   ‚öôÔ∏è  Inference : 5592.59 ms\n",
      "   üì¶ Postprocess: 0.22 ms\n",
      "   ‚è±Ô∏è  Total: 5602.21 ms ‚Üí 0.18 FPS\n",
      "\n",
      "============================================================\n",
      "üî• SSD300 BENCHMARK\n",
      "============================================================\n",
      "\n",
      "üöÄ Benchmarking SSD300: ssd300.pth\n",
      "üìê Input size: (640, 640)\n",
      "üñ•Ô∏è  Device: cpu\n",
      "üìä Running 25 samples (after 5 warmup)\n",
      "\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16_features-amdegroot-88682ab5.pth\" to /home/pi5/.cache/torch/hub/checkpoints/vgg16_features-amdegroot-88682ab5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528M/528M [02:37<00:00, 3.50MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Warmup (5 runs)...\n",
      "\n",
      "‚è±Ô∏è  Running inference on 25 test images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:24<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Average Timing (over 25 images):\n",
      "   üß© Preprocess: 7.29 ms\n",
      "   ‚öôÔ∏è  Inference : 860.88 ms\n",
      "   üì¶ Postprocess: 0.15 ms\n",
      "   ‚è±Ô∏è  Total: 868.33 ms ‚Üí 1.15 FPS\n",
      "\n",
      "============================================================\n",
      "‚úÖ BENCHMARK SUMMARY\n",
      "============================================================\n",
      "               Model                   Backend  Avg Preprocess (ms)  Avg Inference (ms)  Avg Postprocess (ms)  Total (ms)      FPS\n",
      "Faster_RCNN_ResNet50 PyTorch Faster-RCNN (CPU)             9.396381         5592.592163              0.217390 5602.205935 0.178501\n",
      "        SSD300_VGG16      PyTorch SSD300 (CPU)             7.292261          860.882187              0.152407  868.326855 1.151640\n",
      "\n",
      "üíæ Saved results to: ./Eval/detect_eval_results_fps_rcnn_ssd.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_yaml = \"./Dataset/Detect/data_detect_tt100k/data.yaml\"\n",
    "\n",
    "# Model paths\n",
    "models_detection = {\n",
    "    \"Faster_RCNN\": \"./weight/faster_rcnn.pth\",\n",
    "    \"SSD300\": \"./weight/ssd300.pth\",\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- Benchmark Faster R-CNN ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî• FASTER R-CNN BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    result = benchmark_faster_rcnn_inference(\n",
    "        model_path=models_detection[\"Faster_RCNN\"],\n",
    "        data_yaml=data_yaml,\n",
    "        model_name=\"Faster_RCNN_ResNet50\",\n",
    "        input_size=(640, 640),\n",
    "        num_warmup=5,\n",
    "        num_samples=25,\n",
    "        conf_threshold=0.25,\n",
    "        device='cpu'\n",
    "    )\n",
    "    results.append(result)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error benchmarking Faster R-CNN: {e}\")\n",
    "\n",
    "# --- Benchmark SSD300 ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî• SSD300 BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    result = benchmark_ssd300_inference(\n",
    "        model_path=models_detection[\"SSD300\"],\n",
    "        data_yaml=data_yaml,\n",
    "        model_name=\"SSD300_VGG16\",\n",
    "        input_size=(640, 640),\n",
    "        num_warmup=5,\n",
    "        num_samples=25,\n",
    "        conf_threshold=0.25,\n",
    "        device='cpu'\n",
    "    )\n",
    "    results.append(result)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error benchmarking SSD300: {e}\")\n",
    "\n",
    "# --- Print Summary ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ BENCHMARK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "save_path = \"./Eval/detect_eval_results_fps_rcnn_ssd.csv\"\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"\\nüíæ Saved results to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
