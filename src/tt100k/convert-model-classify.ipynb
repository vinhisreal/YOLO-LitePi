{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e286adbb",
   "metadata": {
    "papermill": {
     "duration": 0.004462,
     "end_time": "2025-11-12T11:17:05.437548",
     "exception": false,
     "start_time": "2025-11-12T11:17:05.433086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f49f76a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:17:05.447961Z",
     "iopub.status.busy": "2025-11-12T11:17:05.447633Z",
     "iopub.status.idle": "2025-11-12T11:17:19.882528Z",
     "shell.execute_reply": "2025-11-12T11:17:19.881363Z"
    },
    "papermill": {
     "duration": 14.442428,
     "end_time": "2025-11-12T11:17:19.884257",
     "exception": false,
     "start_time": "2025-11-12T11:17:05.441829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Num classes: 91\n"
     ]
    }
   ],
   "source": [
    "import torch, json, os\n",
    "from torchvision import models\n",
    "\n",
    "root_model = \"/home/pi5/TrafficSign/WeightClassify\"\n",
    "root_data = \"/home/pi5/TrafficSign/Dataset/Classify\"\n",
    "\n",
    "with open(os.path.join(root_data, \"label2idx.json\")) as f:\n",
    "    label2idx = json.load(f)\n",
    "\n",
    "num_classes = len(label2idx)\n",
    "print(\"üîπ Num classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c90b5",
   "metadata": {
    "papermill": {
     "duration": 0.004242,
     "end_time": "2025-11-12T11:17:19.893070",
     "exception": false,
     "start_time": "2025-11-12T11:17:19.888828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export sang ONNX (FP32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0297b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:17:26.079798Z",
     "iopub.status.busy": "2025-11-12T11:17:26.078875Z",
     "iopub.status.idle": "2025-11-12T11:17:26.087738Z",
     "shell.execute_reply": "2025-11-12T11:17:26.086763Z"
    },
    "papermill": {
     "duration": 0.017252,
     "end_time": "2025-11-12T11:17:26.089630",
     "exception": false,
     "start_time": "2025-11-12T11:17:26.072378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, torch\n",
    "\n",
    "def export_onnx(model, model_name, input_size=(3, 64, 64)):\n",
    "    model.eval()\n",
    "    dummy = torch.randn(1, *input_size)\n",
    "\n",
    "    # === T·∫°o th∆∞ m·ª•c export ri√™ng ===\n",
    "    export_dir = f\"/home/pi5/TrafficSign/convert/classify_model/export_onnx/{model_name}\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    # === ƒê∆∞·ªùng d·∫´n l∆∞u file ===\n",
    "    onnx_path = os.path.join(export_dir, f\"{model_name}_fp32.onnx\")\n",
    "\n",
    "    # === Export FP32 ===\n",
    "    torch.onnx.export(\n",
    "        model, dummy, onnx_path,\n",
    "        input_names=['input'], output_names=['output'],\n",
    "        opset_version=18\n",
    "    )\n",
    "    print(f\"‚úÖ Exported FP32: {onnx_path}\")\n",
    "\n",
    "    # === Convert sang FP16 ===\n",
    "    import onnx\n",
    "    from onnxconverter_common import float16\n",
    "\n",
    "    onnx_fp32 = onnx.load(onnx_path)\n",
    "    onnx.save(onnx_fp32, onnx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3f20f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-12T11:17:26.100959Z",
     "iopub.status.busy": "2025-11-12T11:17:26.100084Z",
     "iopub.status.idle": "2025-11-12T11:17:34.060800Z",
     "shell.execute_reply": "2025-11-12T11:17:34.059540Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 7.968975,
     "end_time": "2025-11-12T11:17:34.063148",
     "exception": false,
     "start_time": "2025-11-12T11:17:26.094173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === ResNet18 ===\n",
    "model = models.resnet18()\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(f\"{root_model}/resnet18_best.pth\", map_location=\"cpu\"))\n",
    "export_onnx(model, \"resnet18\")\n",
    "\n",
    "# === EfficientNetB0 ===\n",
    "model = models.efficientnet_b0()\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model.load_state_dict(torch.load(f\"{root_model}/efficientnetb0_best.pth\", map_location=\"cpu\"))\n",
    "export_onnx(model, \"efficientnetb0\")\n",
    "\n",
    "# === MobileNetV2 ===\n",
    "model = models.mobilenet_v2()\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model.load_state_dict(torch.load(f\"{root_model}/mobilenetv2_best.pth\", map_location=\"cpu\"))\n",
    "export_onnx(model, \"mobilenetv2\")\n",
    "\n",
    "# === ShuffleNetV2 ===\n",
    "model = models.shufflenet_v2_x1_0()\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(f\"{root_model}/shufflenetv2_x1_0_best.pth\", map_location=\"cpu\"))\n",
    "export_onnx(model, \"shufflenetv2_x1_0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bcb2d",
   "metadata": {
    "papermill": {
     "duration": 0.005856,
     "end_time": "2025-11-12T11:17:34.075318",
     "exception": false,
     "start_time": "2025-11-12T11:17:34.069462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export sang OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb522f7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:18:03.838903Z",
     "iopub.status.busy": "2025-11-12T11:18:03.838494Z",
     "iopub.status.idle": "2025-11-12T11:18:19.075283Z",
     "shell.execute_reply": "2025-11-12T11:18:19.073846Z"
    },
    "papermill": {
     "duration": 15.249036,
     "end_time": "2025-11-12T11:18:19.078783",
     "exception": false,
     "start_time": "2025-11-12T11:18:03.829747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import openvino as ov\n",
    "\n",
    "# onnx_path = \"/home/pi5/TrafficSign/convert/classify_model/export_onnx/resnet18/resnet18_fp32.onnx\"\n",
    "# output_dir = \"/home/pi5/TrafficSign/convert/classify_model/export_openvino/resnet18\"\n",
    "\n",
    "# core = ov.Core()\n",
    "\n",
    "# # Convert model t·ª´ ONNX sang OpenVINO IR\n",
    "# model = ov.convert_model(onnx_path, framework=\"onnx\")\n",
    "\n",
    "# # Serialize ra file .xml + .bin\n",
    "# ov.save_model(model, f\"{output_dir}/resnet18.xml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a9d8e3",
   "metadata": {
    "papermill": {
     "duration": 0.007877,
     "end_time": "2025-11-12T11:18:19.094541",
     "exception": false,
     "start_time": "2025-11-12T11:18:19.086664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export sang NCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbd2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:02.889248Z",
     "iopub.status.busy": "2025-11-12T11:20:02.888726Z",
     "iopub.status.idle": "2025-11-12T11:20:02.903473Z",
     "shell.execute_reply": "2025-11-12T11:20:02.902420Z"
    },
    "papermill": {
     "duration": 0.060277,
     "end_time": "2025-11-12T11:20:02.905858",
     "exception": false,
     "start_time": "2025-11-12T11:20:02.845581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "def export_to_ncnn(model_name, \n",
    "                   onnx_root=\"/kaggle/working/export_onnx\", \n",
    "                   out_root=\"/kaggle/working/export_ncnn\",\n",
    "                   input_shape=\"[1,3,64,64]\"):\n",
    "    \"\"\"\n",
    "    Export ONE model (model_name) from ONNX ‚Üí NCNN using pnnx converter.\n",
    "    \"\"\"\n",
    "    model_dir = os.path.join(out_root, model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    onnx_path = os.path.join(onnx_root, model_name, f\"{model_name}_fp16.onnx\")\n",
    "    if not os.path.exists(onnx_path):\n",
    "        print(f\"‚ö†Ô∏è Model not found: {onnx_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nüöÄ Exporting {model_name} to NCNN...\")\n",
    "    start = datetime.now()\n",
    "    cmd = [\n",
    "        \"pnnx\", onnx_path,\n",
    "        f\"inputshape={input_shape}f16\",\n",
    "        \"device=cpu\",\n",
    "        f\"outputdir={model_dir}\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        elapsed = (datetime.now() - start).total_seconds()\n",
    "        print(f\"‚úÖ Done {model_name} in {elapsed:.2f}s ‚Üí {model_dir}\")\n",
    "        return {\"model\": model_name, \"status\": \"success\", \"time_s\": elapsed}\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed {model_name}: {e}\")\n",
    "        return {\"model\": model_name, \"status\": \"failed\", \"time_s\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da627c1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:02.987701Z",
     "iopub.status.busy": "2025-11-12T11:20:02.987261Z",
     "iopub.status.idle": "2025-11-12T11:20:08.615485Z",
     "shell.execute_reply": "2025-11-12T11:20:08.614093Z"
    },
    "papermill": {
     "duration": 5.67113,
     "end_time": "2025-11-12T11:20:08.617271",
     "exception": false,
     "start_time": "2025-11-12T11:20:02.946141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_to_ncnn(\"resnet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d104a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:08.748022Z",
     "iopub.status.busy": "2025-11-12T11:20:08.747593Z",
     "iopub.status.idle": "2025-11-12T11:20:12.370107Z",
     "shell.execute_reply": "2025-11-12T11:20:12.368880Z"
    },
    "papermill": {
     "duration": 3.688145,
     "end_time": "2025-11-12T11:20:12.372459",
     "exception": false,
     "start_time": "2025-11-12T11:20:08.684314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_to_ncnn(\"mobilenetv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d107a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:12.471280Z",
     "iopub.status.busy": "2025-11-12T11:20:12.470926Z",
     "iopub.status.idle": "2025-11-12T11:20:16.247060Z",
     "shell.execute_reply": "2025-11-12T11:20:16.245831Z"
    },
    "papermill": {
     "duration": 3.829396,
     "end_time": "2025-11-12T11:20:16.248839",
     "exception": false,
     "start_time": "2025-11-12T11:20:12.419443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_to_ncnn(\"efficientnetb0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235a0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T11:20:16.343148Z",
     "iopub.status.busy": "2025-11-12T11:20:16.342810Z",
     "iopub.status.idle": "2025-11-12T11:20:19.793634Z",
     "shell.execute_reply": "2025-11-12T11:20:19.792442Z"
    },
    "papermill": {
     "duration": 3.499421,
     "end_time": "2025-11-12T11:20:19.795491",
     "exception": false,
     "start_time": "2025-11-12T11:20:16.296070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_to_ncnn(\"shufflenetv2_x1_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4debf3b7",
   "metadata": {
    "papermill": {
     "duration": 0.046064,
     "end_time": "2025-11-12T11:20:19.888048",
     "exception": false,
     "start_time": "2025-11-12T11:20:19.841984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13b755",
   "metadata": {
    "papermill": {
     "duration": 0.044876,
     "end_time": "2025-11-12T11:20:19.977736",
     "exception": false,
     "start_time": "2025-11-12T11:20:19.932860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f585c31",
   "metadata": {
    "papermill": {
     "duration": 0.044916,
     "end_time": "2025-11-12T11:20:20.067621",
     "exception": false,
     "start_time": "2025-11-12T11:20:20.022705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fd8445c",
   "metadata": {
    "papermill": {
     "duration": 0.044488,
     "end_time": "2025-11-12T11:20:20.156276",
     "exception": false,
     "start_time": "2025-11-12T11:20:20.111788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9080c006",
   "metadata": {
    "papermill": {
     "duration": 0.046633,
     "end_time": "2025-11-12T11:20:20.248199",
     "exception": false,
     "start_time": "2025-11-12T11:20:20.201566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, time, json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openvino.runtime import Core\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def evaluate_openvino_model(xml_path, idx2label_path, data_dir = \"/home/pi5/TrafficSign/Dataset/Classify/test\"\n",
    ", img_size=64, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Benchmark OpenVINO model (FP32) on CPU to match PyTorch evaluation settings.\n",
    "    \"\"\"\n",
    "    # ==== Chu·∫©n b·ªã d·ªØ li·ªáu ====\n",
    "    idx2label = json.load(open(idx2label_path))\n",
    "    label2idx = {v: k for k, v in idx2label.items()}\n",
    "\n",
    "    # L·∫•y ·∫£nh m·∫´u c·ªë ƒë·ªãnh\n",
    "    samples = []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        imgs = [os.path.join(root, f) for f in files if f.lower().endswith(('.jpg', '.png'))]\n",
    "        for f in imgs:\n",
    "            samples.append((f, os.path.basename(root)))\n",
    "\n",
    "    if n_samples:\n",
    "        samples = samples[:n_samples]\n",
    "\n",
    "    # ==== Ti·ªÅn x·ª≠ l√Ω ·∫£nh (gi·ªëng PyTorch ImageNet) ====\n",
    "    def preprocess_image(path):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "        std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "        img = (img - mean) / std\n",
    "        img = img.transpose(2, 0, 1)[None, ...]  # NCHW\n",
    "        return img\n",
    "\n",
    "    # ==== Kh·ªüi t·∫°o OpenVINO ====\n",
    "    core = Core()\n",
    "    bin_path = xml_path.replace(\".xml\", \".bin\")\n",
    "    model = core.read_model(xml_path, bin_path)\n",
    "    compiled = core.compile_model(model, \"CPU\")\n",
    "\n",
    "    input_tensor = compiled.inputs[0]\n",
    "    output_tensor = compiled.outputs[0]\n",
    "\n",
    "    preds_all, labels_all = [], []\n",
    "    total_time = 0.0\n",
    "\n",
    "    # ==== Inference loop ====\n",
    "    for img_path, true_label in tqdm(samples, desc=f\"Evaluating {os.path.basename(xml_path)}\"):\n",
    "        img = preprocess_image(img_path)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        result = compiled([img])[output_tensor]\n",
    "        total_time += time.perf_counter() - start\n",
    "\n",
    "        pred_label = str(int(np.argmax(result)))\n",
    "        preds_all.append(pred_label)\n",
    "        labels_all.append(label2idx[true_label])\n",
    "\n",
    "    # ==== Metrics ====\n",
    "    preds_int = list(map(int, preds_all))\n",
    "    labels_int = list(map(int, labels_all))\n",
    "\n",
    "    acc = accuracy_score(labels_int, preds_int)\n",
    "    prec = precision_score(labels_int, preds_int, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(labels_int, preds_int, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(labels_int, preds_int, average=\"macro\", zero_division=0)\n",
    "    fps = len(samples) / total_time if total_time > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Model\": os.path.basename(xml_path).replace(\".xml\", \"\"),\n",
    "        \"Device\": \"CPU\",\n",
    "        \"Precision\": \"FP32\",\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"PrecisionScore\": round(prec, 4),\n",
    "        \"Recall\": round(rec, 4),\n",
    "        \"F1\": round(f1, 4),\n",
    "        \"FPS\": round(fps, 2),\n",
    "        \"Time_per_img(s)\": round(total_time / len(samples), 4),\n",
    "        \"Samples\": len(samples)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9836e140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating resnet18_fp32.xml: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:05<00:00, 182.77it/s]\n",
      "Evaluating mobilenetv2_fp32.xml: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:03<00:00, 288.07it/s]\n",
      "Evaluating efficientnetb0_fp32.xml: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:07<00:00, 133.05it/s]\n",
      "Evaluating shufflenetv2_x1_0_fp32.xml: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:03<00:00, 251.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6411f\">\n",
       "  <caption>OpenVINO FP32 (CPU) Inference Benchmark</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_6411f_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6411f_level0_col1\" class=\"col_heading level0 col1\" >Device</th>\n",
       "      <th id=\"T_6411f_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_6411f_level0_col3\" class=\"col_heading level0 col3\" >Accuracy</th>\n",
       "      <th id=\"T_6411f_level0_col4\" class=\"col_heading level0 col4\" >PrecisionScore</th>\n",
       "      <th id=\"T_6411f_level0_col5\" class=\"col_heading level0 col5\" >Recall</th>\n",
       "      <th id=\"T_6411f_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
       "      <th id=\"T_6411f_level0_col7\" class=\"col_heading level0 col7\" >FPS</th>\n",
       "      <th id=\"T_6411f_level0_col8\" class=\"col_heading level0 col8\" >Time_per_img(s)</th>\n",
       "      <th id=\"T_6411f_level0_col9\" class=\"col_heading level0 col9\" >Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_6411f_row0_col0\" class=\"data row0 col0\" >resnet18_fp32</td>\n",
       "      <td id=\"T_6411f_row0_col1\" class=\"data row0 col1\" >CPU</td>\n",
       "      <td id=\"T_6411f_row0_col2\" class=\"data row0 col2\" >FP32</td>\n",
       "      <td id=\"T_6411f_row0_col3\" class=\"data row0 col3\" >0.979000</td>\n",
       "      <td id=\"T_6411f_row0_col4\" class=\"data row0 col4\" >0.443600</td>\n",
       "      <td id=\"T_6411f_row0_col5\" class=\"data row0 col5\" >0.428400</td>\n",
       "      <td id=\"T_6411f_row0_col6\" class=\"data row0 col6\" >0.435700</td>\n",
       "      <td id=\"T_6411f_row0_col7\" class=\"data row0 col7\" >200.480000</td>\n",
       "      <td id=\"T_6411f_row0_col8\" class=\"data row0 col8\" >0.005000</td>\n",
       "      <td id=\"T_6411f_row0_col9\" class=\"data row0 col9\" >1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6411f_row1_col0\" class=\"data row1 col0\" >mobilenetv2_fp32</td>\n",
       "      <td id=\"T_6411f_row1_col1\" class=\"data row1 col1\" >CPU</td>\n",
       "      <td id=\"T_6411f_row1_col2\" class=\"data row1 col2\" >FP32</td>\n",
       "      <td id=\"T_6411f_row1_col3\" class=\"data row1 col3\" >0.980000</td>\n",
       "      <td id=\"T_6411f_row1_col4\" class=\"data row1 col4\" >0.443800</td>\n",
       "      <td id=\"T_6411f_row1_col5\" class=\"data row1 col5\" >0.425800</td>\n",
       "      <td id=\"T_6411f_row1_col6\" class=\"data row1 col6\" >0.434400</td>\n",
       "      <td id=\"T_6411f_row1_col7\" class=\"data row1 col7\" >334.940000</td>\n",
       "      <td id=\"T_6411f_row1_col8\" class=\"data row1 col8\" >0.003000</td>\n",
       "      <td id=\"T_6411f_row1_col9\" class=\"data row1 col9\" >1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6411f_row2_col0\" class=\"data row2 col0\" >efficientnetb0_fp32</td>\n",
       "      <td id=\"T_6411f_row2_col1\" class=\"data row2 col1\" >CPU</td>\n",
       "      <td id=\"T_6411f_row2_col2\" class=\"data row2 col2\" >FP32</td>\n",
       "      <td id=\"T_6411f_row2_col3\" class=\"data row2 col3\" >0.874000</td>\n",
       "      <td id=\"T_6411f_row2_col4\" class=\"data row2 col4\" >0.294000</td>\n",
       "      <td id=\"T_6411f_row2_col5\" class=\"data row2 col5\" >0.226100</td>\n",
       "      <td id=\"T_6411f_row2_col6\" class=\"data row2 col6\" >0.248300</td>\n",
       "      <td id=\"T_6411f_row2_col7\" class=\"data row2 col7\" >142.510000</td>\n",
       "      <td id=\"T_6411f_row2_col8\" class=\"data row2 col8\" >0.007000</td>\n",
       "      <td id=\"T_6411f_row2_col9\" class=\"data row2 col9\" >1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6411f_row3_col0\" class=\"data row3 col0\" >shufflenetv2_x1_0_fp32</td>\n",
       "      <td id=\"T_6411f_row3_col1\" class=\"data row3 col1\" >CPU</td>\n",
       "      <td id=\"T_6411f_row3_col2\" class=\"data row3 col2\" >FP32</td>\n",
       "      <td id=\"T_6411f_row3_col3\" class=\"data row3 col3\" >0.884000</td>\n",
       "      <td id=\"T_6411f_row3_col4\" class=\"data row3 col4\" >0.330300</td>\n",
       "      <td id=\"T_6411f_row3_col5\" class=\"data row3 col5\" >0.267600</td>\n",
       "      <td id=\"T_6411f_row3_col6\" class=\"data row3 col6\" >0.290800</td>\n",
       "      <td id=\"T_6411f_row3_col7\" class=\"data row3 col7\" >285.750000</td>\n",
       "      <td id=\"T_6411f_row3_col8\" class=\"data row3 col8\" >0.003500</td>\n",
       "      <td id=\"T_6411f_row3_col9\" class=\"data row3 col9\" >1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fff281f39d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === ƒê∆∞·ªùng d·∫´n ===\n",
    "base_dir = \"/home/pi5/TrafficSign/convert/classify_model/export_openvino\"\n",
    "data_dir = \"/home/pi5/TrafficSign/Dataset/Classify/test\"\n",
    "idx2label_path = \"/home/pi5/TrafficSign/Dataset/Classify/idx2label.json\"\n",
    "\n",
    "# === Danh s√°ch model ===\n",
    "models = [\"resnet18\",\"mobilenetv2\",\"efficientnetb0\", \"shufflenetv2_x1_0\"]\n",
    "\n",
    "\n",
    "results = []\n",
    "for name in models:\n",
    "    xml_path = os.path.join(base_dir, name, f\"{name}_fp32.xml\")\n",
    "    if not os.path.exists(xml_path):\n",
    "        print(f\"‚ö†Ô∏è Missing: {xml_path}\")\n",
    "        continue\n",
    "    res = evaluate_openvino_model(xml_path, idx2label_path, data_dir, img_size=64)\n",
    "    results.append(res)\n",
    "\n",
    "# === K·∫øt qu·∫£ ===\n",
    "df_ov = pd.DataFrame(results)\n",
    "display(df_ov.style.hide(axis=\"index\").set_caption(\"OpenVINO FP32 (CPU) Inference Benchmark\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd3e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating efficientnetb0_fp32.xml:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5854/9226 [01:30<00:51, 64.96it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ö†Ô∏è Missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxml_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m res = \u001b[43mevaluate_openvino_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx2label_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m results.append(res)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mevaluate_openvino_model\u001b[39m\u001b[34m(xml_path, data_dir, idx2label_path, img_size, n_samples)\u001b[39m\n\u001b[32m     54\u001b[39m img = preprocess_image(img_path)\n\u001b[32m     56\u001b[39m start = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m result = \u001b[43mcompiled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[output_tensor]\n\u001b[32m     58\u001b[39m total_time += time.perf_counter() - start\n\u001b[32m     60\u001b[39m pred_label = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(np.argmax(result)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TrafficSign/tsr/lib/python3.13/site-packages/openvino/_ov_api.py:440\u001b[39m, in \u001b[36mCompiledModel.__call__\u001b[39m\u001b[34m(self, inputs, share_inputs, share_outputs, decode_strings)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._infer_request \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    438\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_request = \u001b[38;5;28mself\u001b[39m.create_infer_request()\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_infer_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshare_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshare_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshare_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshare_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_strings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_strings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TrafficSign/tsr/lib/python3.13/site-packages/openvino/_ov_api.py:184\u001b[39m, in \u001b[36mInferRequest.infer\u001b[39m\u001b[34m(self, inputs, share_inputs, share_outputs, decode_strings)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer\u001b[39m(\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    109\u001b[39m     inputs: Any = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    113\u001b[39m     decode_strings: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    114\u001b[39m ) -> OVDict:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Infers specified input(s) in synchronous mode.\u001b[39;00m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    Blocks all methods of InferRequest while request is running.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m    :rtype: OVDict\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m OVDict(\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_data_dispatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_shared\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshare_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshare_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_strings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_strings\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "models2 = [\"efficientnetb0\", \"shufflenetv2_x1_0\"]\n",
    "results = []\n",
    "for name in models2:\n",
    "    xml_path = os.path.join(base_dir, name, f\"{name}_fp32.xml\")\n",
    "    if not os.path.exists(xml_path):\n",
    "        print(f\"‚ö†Ô∏è Missing: {xml_path}\")\n",
    "        continue\n",
    "    res = evaluate_openvino_model(xml_path, data_dir, idx2label_path, img_size=64)\n",
    "    results.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ov = pd.DataFrame(results)\n",
    "display(df_ov.style.hide(axis=\"index\").set_caption(\"OpenVINO FP32 (CPU) Inference Benchmark\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fdf876",
   "metadata": {
    "papermill": {
     "duration": 0.047457,
     "end_time": "2025-11-12T11:20:20.341527",
     "exception": false,
     "start_time": "2025-11-12T11:20:20.294070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference NCNN"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 274826856,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 276190662,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 202.256208,
   "end_time": "2025-11-12T11:20:22.213304",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-12T11:16:59.957096",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
