{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59584eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-11-16 23:01:18.864871317 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card1/device/vendor\"\u001b[m\n",
      "/home/pi5/TrafficSign/venv_tsr/lib/python3.13/site-packages/openvino/runtime/__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import onnxruntime as ort\n",
    "from openvino.runtime import Core\n",
    "import ncnn\n",
    "import time\n",
    "import random\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad05458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114)):\n",
    "    \"\"\"Resize and pad image to new_shape with letterbox\"\"\"\n",
    "    shape = img.shape[:2]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "    \n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]\n",
    "    \n",
    "    dw /= 2\n",
    "    dh /= 2\n",
    "    \n",
    "    if shape[::-1] != new_unpad:\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    \n",
    "    return img, r, (dw, dh)\n",
    "\n",
    "\n",
    "def nms_numpy(boxes, scores, iou_threshold=0.45):\n",
    "    \"\"\"Non-Maximum Suppression - DÃ™NG CHUNG CHO Táº¤T Cáº¢\"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    x1, y1, x2, y2 = boxes.T\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        \n",
    "        if len(order) == 1:\n",
    "            break\n",
    "            \n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1)\n",
    "        h = np.maximum(0.0, yy2 - yy1)\n",
    "        inter = w * h\n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-6)\n",
    "\n",
    "        inds = np.where(iou <= iou_threshold)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "def preprocess_image(img, input_size=(640, 640)):\n",
    "    \"\"\"\n",
    "    Preprocess CHUNG cho ONNX/OpenVINO/NCNN (numpy version)\n",
    "    Tráº£ vá» numpy array Ä‘á»ƒ fair\n",
    "    \"\"\"\n",
    "    img_resized, ratio, (dw, dh) = letterbox(img, new_shape=input_size)\n",
    "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "    img_normalized = img_rgb.astype(np.float32) / 255.0\n",
    "    img_transposed = img_normalized.transpose(2, 0, 1)\n",
    "    img_batch = np.expand_dims(img_transposed, axis=0)\n",
    "    \n",
    "    return img_batch, ratio, (dw, dh)\n",
    "\n",
    "\n",
    "def postprocess_with_nms(output, orig_shape, ratio, pad, conf_threshold=0.25, iou_threshold=0.45):\n",
    "    \"\"\"\n",
    "    Postprocess CHUNG CHO Táº¤T Cáº¢ BACKEND (cÃ³ NMS)\n",
    "    Äáº£m báº£o tÃ­nh cÃ´ng báº±ng\n",
    "    \"\"\"\n",
    "    # Normalize shape to (1, 84, 8400)\n",
    "    if isinstance(output, ncnn.Mat):\n",
    "        output = np.array(output)\n",
    "    \n",
    "    if output.ndim == 2:\n",
    "        output = np.expand_dims(output, axis=0)\n",
    "    if output.shape[-1] == 84:\n",
    "        output = output.transpose(0, 2, 1)\n",
    "    \n",
    "    predictions = output[0]  # (84, 8400)\n",
    "    boxes = predictions[:4].T  # (8400, 4)\n",
    "    scores = predictions[4:].T  # (8400, num_classes)\n",
    "    \n",
    "    # Get max score and class\n",
    "    class_scores = np.max(scores, axis=1)\n",
    "    class_ids = np.argmax(scores, axis=1)\n",
    "    \n",
    "    # Filter by confidence\n",
    "    mask = class_scores > conf_threshold\n",
    "    boxes = boxes[mask]\n",
    "    scores = class_scores[mask]\n",
    "    class_ids = class_ids[mask]\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        return np.empty((0, 4)), np.empty((0,)), np.empty((0,))\n",
    "    \n",
    "    # Convert xywh to xyxy\n",
    "    x_center, y_center, width, height = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
    "    x1 = x_center - width / 2\n",
    "    y1 = y_center - height / 2\n",
    "    x2 = x_center + width / 2\n",
    "    y2 = y_center + height / 2\n",
    "    boxes_xyxy = np.stack([x1, y1, x2, y2], axis=1)\n",
    "    \n",
    "    # Scale back to original image\n",
    "    boxes_xyxy[:, [0, 2]] -= pad[0]\n",
    "    boxes_xyxy[:, [1, 3]] -= pad[1]\n",
    "    boxes_xyxy /= ratio\n",
    "    \n",
    "    # Clip to image boundaries\n",
    "    boxes_xyxy[:, [0, 2]] = np.clip(boxes_xyxy[:, [0, 2]], 0, orig_shape[1])\n",
    "    boxes_xyxy[:, [1, 3]] = np.clip(boxes_xyxy[:, [1, 3]], 0, orig_shape[0])\n",
    "    \n",
    "    # Apply NMS per class\n",
    "    nms_indices = []\n",
    "    for cls in np.unique(class_ids):\n",
    "        cls_mask = class_ids == cls\n",
    "        keep = nms_numpy(boxes_xyxy[cls_mask], scores[cls_mask], iou_threshold)\n",
    "        nms_indices.extend(np.where(cls_mask)[0][keep])\n",
    "    \n",
    "    if len(nms_indices) > 0:\n",
    "        nms_indices = np.array(nms_indices)\n",
    "        boxes_xyxy = boxes_xyxy[nms_indices]\n",
    "        scores = scores[nms_indices]\n",
    "        class_ids = class_ids[nms_indices]\n",
    "    else:\n",
    "        boxes_xyxy = np.empty((0, 4))\n",
    "        scores = np.empty((0,))\n",
    "        class_ids = np.empty((0,))\n",
    "    \n",
    "    return boxes_xyxy, scores, class_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb5b5f",
   "metadata": {},
   "source": [
    "# EVAL PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a1736a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fff421ac1b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a5d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_pytorch_inference(\n",
    "    model_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    iou_threshold=0.45,\n",
    "    device='cpu'\n",
    "):\n",
    "    \n",
    "    \"\"\"Benchmark PyTorch model vá»›i cÃ¹ng preprocessing/postprocessing\"\"\"\n",
    "    print(f\"\\nğŸš€ Benchmarking PyTorch: {Path(model_path).name}\")\n",
    "    print(f\"ğŸ“ Input size: {input_size}\")\n",
    "    print(f\"ğŸ–¥ï¸  Device: {device}\")\n",
    "    print(f\"ğŸ“Š Running {num_samples} samples (after {num_warmup} warmup)\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    model = YOLO(model_path)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_config.get('val', 'valid/images')\n",
    "    image_files = list(val_path.glob('*.jpg')) + list(val_path.glob('*.png'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "        \n",
    "    # Warmup\n",
    "    print(f\"ğŸ”¥ Warmup ({num_warmup} runs)...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        input_tensor, _, _ = preprocess_image(img, input_size=input_size)\n",
    "        input_torch = torch.from_numpy(input_tensor).to(device)\n",
    "        with torch.no_grad():\n",
    "            _ = model.model(input_torch)\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Running inference on {len(sample_images)} test images...\")\n",
    "    for img_path in sample_images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        input_tensor, ratio, pad = preprocess_image(img, input_size=input_size)\n",
    "        input_torch = torch.from_numpy(input_tensor).to(device)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model.model(input_torch)\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # Postprocess\n",
    "        output_np = outputs[0].cpu().numpy() if isinstance(outputs[0], torch.Tensor) else outputs[0]\n",
    "        boxes, scores, class_ids = postprocess_with_nms(\n",
    "            output_np, (orig_h, orig_w), ratio, pad, conf_threshold, iou_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   ğŸ§© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   âš™ï¸  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   ğŸ“¦ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   â±ï¸  Total: {total_ms:.2f} ms â†’ {fps:.2f} FPS\")\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": f\"PyTorch ({device.upper()})\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f2fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_onnx_inference(\n",
    "    onnx_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    iou_threshold=0.45,\n",
    "    device_provider='CPUExecutionProvider'\n",
    "):\n",
    "    \"\"\"Benchmark ONNX vá»›i postprocess GIá»NG Há»†T cÃ¡c backend khÃ¡c\"\"\"\n",
    "    print(f\"\\nğŸš€ Benchmarking ONNX: {Path(onnx_path).name}\")\n",
    "    print(f\"âš™ï¸  Provider: {device_provider}\")\n",
    "    print(f\"ğŸ“ Input size: {input_size}\")\n",
    "    print(f\"ğŸ“Š Running {num_samples} images (after {num_warmup} warmup)\")\n",
    "    \n",
    "    # Load model\n",
    "    session = ort.InferenceSession(onnx_path, providers=[device_provider])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_config.get('val', 'valid/images')\n",
    "    image_files = list(val_path.glob('*.jpg')) + list(val_path.glob('*.png'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    # Warmup\n",
    "    print(f\"\\nğŸ”¥ Warmup ({num_warmup} runs)...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        input_tensor, _, _ = preprocess_image(img, input_size=input_size)\n",
    "        _ = session.run(None, {input_name: input_tensor})\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Running inference on {len(sample_images)} test images...\")\n",
    "    for img_path in sample_images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        input_tensor, ratio, pad = preprocess_image(img, input_size=input_size)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        outputs = session.run(None, {input_name: input_tensor})\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # Postprocess (DÃ™NG HÃ€M CHUNG)\n",
    "        boxes, scores, class_ids = postprocess_with_nms(\n",
    "            outputs[0], (orig_h, orig_w), ratio, pad, conf_threshold, iou_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   ğŸ§© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   âš™ï¸  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   ğŸ“¦ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   â±ï¸  Total: {total_ms:.2f} ms â†’ {fps:.2f} FPS\")\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": \"ONNX (CPU)\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476fe696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_openvino_inference(\n",
    "    model_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    iou_threshold=0.45,\n",
    "    device=\"CPU\"\n",
    "):\n",
    "    \"\"\"Benchmark OpenVINO vá»›i postprocess GIá»NG Há»†T cÃ¡c backend khÃ¡c\"\"\"\n",
    "    print(f\"\\nğŸš€ Benchmarking OpenVINO: {Path(model_path).name}\")\n",
    "    print(f\"ğŸ“ Input size: {input_size}\")\n",
    "    print(f\"ğŸ–¥ï¸  Device: {device}\")\n",
    "    print(f\"ğŸ“Š Running {num_samples} samples (after {num_warmup} warmup)\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    ie = Core()\n",
    "    model = ie.read_model(model=model_path)\n",
    "    compiled_model = ie.compile_model(model=model, device_name=device)\n",
    "    input_layer = compiled_model.input(0)\n",
    "    output_layer = compiled_model.output(0)\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_cfg = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_cfg.get(\"val\", \"valid/images\")\n",
    "    image_files = list(val_path.glob(\"*.jpg\")) + list(val_path.glob(\"*.png\"))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    # Warmup\n",
    "    print(f\"ğŸ”¥ Warming up for {num_warmup} runs...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        input_tensor, _, _ = preprocess_image(img, input_size=input_size)\n",
    "        _ = compiled_model([input_tensor])[output_layer]\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Running timed inference on {len(sample_images)} test images...\")\n",
    "    for img_path in sample_images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        input_tensor, ratio, pad = preprocess_image(img, input_size=input_size)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        outputs = compiled_model([input_tensor])[output_layer]\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # Postprocess (DÃ™NG HÃ€M CHUNG)\n",
    "        boxes, scores, class_ids = postprocess_with_nms(\n",
    "            outputs, (orig_h, orig_w), ratio, pad, conf_threshold, iou_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   ğŸ§© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   âš™ï¸  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   ğŸ“¦ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   â±ï¸  Total: {total_ms:.2f} ms â†’ {fps:.2f} FPS\")\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": \"OpenVINO (CPU)\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1da44eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_ncnn(img, input_size=(640, 640)):\n",
    "    \"\"\"\n",
    "    Preprocess cho NCNN - convert sang ncnn.Mat tá»« numpy array\n",
    "    Äá»ƒ fair, ta váº«n dÃ¹ng letterbox giá»‘ng cÃ¡c backend khÃ¡c\n",
    "    \"\"\"\n",
    "    # DÃ¹ng letterbox chung\n",
    "    img_resized, ratio, (dw, dh) = letterbox(img, new_shape=input_size)\n",
    "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to ncnn.Mat\n",
    "    mat_in = ncnn.Mat.from_pixels(\n",
    "        img_rgb,\n",
    "        ncnn.Mat.PixelType.PIXEL_RGB,\n",
    "        img_rgb.shape[1],\n",
    "        img_rgb.shape[0]\n",
    "    )\n",
    "    \n",
    "    # Normalize\n",
    "    mean_vals = [0, 0, 0]\n",
    "    norm_vals = [1/255.0, 1/255.0, 1/255.0]\n",
    "    mat_in.substract_mean_normalize(mean_vals, norm_vals)\n",
    "    \n",
    "    return mat_in, ratio, (dw, dh)\n",
    "\n",
    "\n",
    "def benchmark_ncnn_inference(\n",
    "    param_path,\n",
    "    bin_path,\n",
    "    data_yaml,\n",
    "    model_name,\n",
    "    input_size=(640, 640),\n",
    "    num_warmup=5,\n",
    "    num_samples=50,\n",
    "    conf_threshold=0.25,\n",
    "    iou_threshold=0.45,\n",
    "    input_name=\"in0\",\n",
    "    output_name=\"out0\",\n",
    "    use_gpu=False,\n",
    "    num_threads=4,\n",
    "):\n",
    "    \"\"\"Benchmark NCNN vá»›i postprocess GIá»NG Há»†T cÃ¡c backend khÃ¡c\"\"\"\n",
    "    print(f\"\\nğŸš€ Benchmarking NCNN: {Path(param_path).stem}\")\n",
    "    print(f\"ğŸ“¦ Model: {param_path}\")\n",
    "    print(f\"ğŸ§© Device: {'GPU (Vulkan)' if use_gpu else f'CPU ({num_threads} threads)'}\")\n",
    "    print(f\"ğŸ“ Input size: {input_size}\")\n",
    "    print(f\"ğŸ“Š Running {num_samples} images (after {num_warmup} warmup)\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    net = ncnn.Net()\n",
    "    net.opt.use_vulkan_compute = use_gpu\n",
    "    net.opt.num_threads = num_threads\n",
    "    \n",
    "    if net.load_param(param_path) != 0:\n",
    "        raise RuntimeError(f\"Failed to load param: {param_path}\")\n",
    "    if net.load_model(bin_path) != 0:\n",
    "        raise RuntimeError(f\"Failed to load bin: {bin_path}\")\n",
    "    \n",
    "    # Load dataset\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    dataset_root = Path(data_yaml).parent\n",
    "    val_path = dataset_root / data_config.get('val', 'valid/images')\n",
    "    image_files = list(val_path.glob('*.jpg')) + list(val_path.glob('*.png'))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        raise ValueError(f\"No images found in {val_path}\")\n",
    "    \n",
    "    sample_images = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    # Warmup\n",
    "    print(f\"ğŸ”¥ Warmup ({num_warmup} runs)...\")\n",
    "    for _ in range(num_warmup):\n",
    "        img = cv2.imread(str(random.choice(sample_images)))\n",
    "        mat_in, _, _ = preprocess_image_ncnn(img, input_size=input_size)\n",
    "        ex = net.create_extractor()\n",
    "        ex.input(input_name, mat_in)\n",
    "        ex.extract(output_name)\n",
    "    \n",
    "    # Benchmark\n",
    "    preprocess_times, inference_times, postprocess_times = [], [], []\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Running inference on {len(sample_images)} test images...\")\n",
    "    for img_path in sample_images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        t0 = time.time()\n",
    "        mat_in, ratio, pad = preprocess_image_ncnn(img, input_size=input_size)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Inference\n",
    "        ex = net.create_extractor()\n",
    "        ex.input(input_name, mat_in)\n",
    "        ret, mat_out = ex.extract(output_name)\n",
    "        t2 = time.time()\n",
    "        \n",
    "        if ret != 0:\n",
    "            print(f\"âš ï¸  Failed inference on {img_path.name}\")\n",
    "            continue\n",
    "        \n",
    "        # Postprocess (DÃ™NG HÃ€M CHUNG)\n",
    "        output_array = np.array(mat_out)\n",
    "        boxes, scores, class_ids = postprocess_with_nms(\n",
    "            output_array, (orig_h, orig_w), ratio, pad, conf_threshold, iou_threshold\n",
    "        )\n",
    "        t3 = time.time()\n",
    "        \n",
    "        preprocess_times.append(t1 - t0)\n",
    "        inference_times.append(t2 - t1)\n",
    "        postprocess_times.append(t3 - t2)\n",
    "    \n",
    "    # Summary\n",
    "    avg_pre = np.mean(preprocess_times) * 1000\n",
    "    avg_inf = np.mean(inference_times) * 1000\n",
    "    avg_post = np.mean(postprocess_times) * 1000\n",
    "    total_ms = avg_pre + avg_inf + avg_post\n",
    "    fps = 1000 / total_ms\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Average Timing (over {len(sample_images)} images):\")\n",
    "    print(f\"   ğŸ§© Preprocess: {avg_pre:.2f} ms\")\n",
    "    print(f\"   âš™ï¸  Inference : {avg_inf:.2f} ms\")\n",
    "    print(f\"   ğŸ“¦ Postprocess: {avg_post:.2f} ms\")\n",
    "    print(f\"   â±ï¸  Total: {total_ms:.2f} ms â†’ {fps:.2f} FPS\\n\")\n",
    "    \n",
    "    device_name = \"GPU (Vulkan)\" if use_gpu else f\"CPU ({num_threads}t)\"\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Backend\": f\"NCNN ({device_name})\",\n",
    "        \"Avg Preprocess (ms)\": avg_pre,\n",
    "        \"Avg Inference (ms)\": avg_inf,\n",
    "        \"Avg Postprocess (ms)\": avg_post,\n",
    "        \"Total (ms)\": total_ms,\n",
    "        \"FPS\": fps,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64d0f8",
   "metadata": {},
   "source": [
    "### RUN EVAL FPS PYTORCH ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f822c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ”¥ PYTORCH BENCHMARK\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Benchmarking PyTorch: yolo5.pt\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: cpu\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.98 ms\n",
      "   âš™ï¸  Inference : 390.51 ms\n",
      "   ğŸ“¦ Postprocess: 0.45 ms\n",
      "   â±ï¸  Total: 398.94 ms â†’ 2.51 FPS\n",
      "\n",
      "ğŸš€ Benchmarking PyTorch: yolo8.pt\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: cpu\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.84 ms\n",
      "   âš™ï¸  Inference : 420.25 ms\n",
      "   ğŸ“¦ Postprocess: 0.47 ms\n",
      "   â±ï¸  Total: 428.56 ms â†’ 2.33 FPS\n",
      "\n",
      "ğŸš€ Benchmarking PyTorch: yolo11.pt\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: cpu\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.90 ms\n",
      "   âš™ï¸  Inference : 394.74 ms\n",
      "   ğŸ“¦ Postprocess: 0.48 ms\n",
      "   â±ï¸  Total: 403.12 ms â†’ 2.48 FPS\n",
      "\n",
      "ğŸš€ Benchmarking PyTorch: yolo_plus_v2.pt\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: cpu\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.84 ms\n",
      "   âš™ï¸  Inference : 311.72 ms\n",
      "   ğŸ“¦ Postprocess: 0.46 ms\n",
      "   â±ï¸  Total: 320.02 ms â†’ 3.12 FPS\n",
      "\n",
      "============================================================\n",
      "ğŸ”¥ ONNX BENCHMARK\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Benchmarking ONNX: yolo5.onnx\n",
      "âš™ï¸  Provider: CPUExecutionProvider\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.79 ms\n",
      "   âš™ï¸  Inference : 129.98 ms\n",
      "   ğŸ“¦ Postprocess: 0.45 ms\n",
      "   â±ï¸  Total: 138.22 ms â†’ 7.23 FPS\n",
      "\n",
      "ğŸš€ Benchmarking ONNX: yolo8.onnx\n",
      "âš™ï¸  Provider: CPUExecutionProvider\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.77 ms\n",
      "   âš™ï¸  Inference : 140.10 ms\n",
      "   ğŸ“¦ Postprocess: 0.46 ms\n",
      "   â±ï¸  Total: 148.33 ms â†’ 6.74 FPS\n",
      "\n",
      "ğŸš€ Benchmarking ONNX: yolo11.onnx\n",
      "âš™ï¸  Provider: CPUExecutionProvider\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.64 ms\n",
      "   âš™ï¸  Inference : 141.23 ms\n",
      "   ğŸ“¦ Postprocess: 0.46 ms\n",
      "   â±ï¸  Total: 149.33 ms â†’ 6.70 FPS\n",
      "\n",
      "ğŸš€ Benchmarking ONNX: yolo_plus.onnx\n",
      "âš™ï¸  Provider: CPUExecutionProvider\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.60 ms\n",
      "   âš™ï¸  Inference : 101.17 ms\n",
      "   ğŸ“¦ Postprocess: 0.44 ms\n",
      "   â±ï¸  Total: 109.22 ms â†’ 9.16 FPS\n",
      "\n",
      "============================================================\n",
      "âœ… BENCHMARK SUMMARY\n",
      "============================================================\n",
      "      Model       Backend  Avg Preprocess (ms)  Avg Inference (ms)  Avg Postprocess (ms)  Total (ms)      FPS\n",
      "    YOLOv5n PyTorch (CPU)             7.982731          390.507791              0.451057  398.941579 2.506633\n",
      "    YOLOv8n PyTorch (CPU)             7.838256          420.246987              0.469940  428.555183 2.333422\n",
      "    YOLO11n PyTorch (CPU)             7.904437          394.735544              0.477245  403.117225 2.480668\n",
      "yolo_custom PyTorch (CPU)             7.842205          311.720452              0.459964  320.022621 3.124779\n",
      "    YOLOv5n    ONNX (CPU)             7.785389          129.979558              0.453262  138.218210 7.234937\n",
      "    YOLOv8n    ONNX (CPU)             7.770267          140.098655              0.464320  148.333242 6.741577\n",
      "    YOLO11n    ONNX (CPU)             7.639096          141.233957              0.456648  149.329700 6.696591\n",
      "yolo_custom    ONNX (CPU)             7.604930          101.170630              0.443389  109.218950 9.155920\n",
      "\n",
      "ğŸ’¾ Saved results to: /home/pi5/TrafficSign/TT100K/Eval/FPS/detect_eval_results_fps_v5_8_11_custom.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataset path\n",
    "data_yaml = \"./Dataset/Detect/data_detect_tt100k/data.yaml\"\n",
    "\n",
    "# Model paths\n",
    "models_pt = {\n",
    "    \"YOLOv5n\": \"./weight/yolo5.pt\",\n",
    "    \"YOLOv8n\": \"./weight/yolo8.pt\",\n",
    "    \"YOLO11n\": \"./weight/yolo11.pt\",\n",
    "    \"yolo_custom\": \"./weight/yolo_plus/yolo_plus_v2.pt\",\n",
    "}\n",
    "\n",
    "models_onnx = {\n",
    "    \"YOLOv5n\": \"./convert/model/yolo5/yolo5.onnx\",\n",
    "    \"YOLOv8n\": \"./convert/model/yolo8/yolo8.onnx\",\n",
    "    \"YOLO11n\": \"./convert/model/yolo11/yolo11.onnx\",\n",
    "    \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus.onnx\",\n",
    "\n",
    "}\n",
    "\n",
    "# models_openvino = {\n",
    "#     \"YOLOv5n\": \"./convert/model/yolov5/yolo5_openvino_model/yolo5.xml\",\n",
    "#     \"YOLOv8n\": \"./convert/model/yolov8/yolo8_openvino_model/yolo8.xml\",\n",
    "#     \"YOLO11n\": \"./convert/model/yolov11/yolo11_openvino_model/yolo11.xml\",\n",
    "#     \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus_openvino_model/yolo_plus.xml\",\n",
    "# }\n",
    "\n",
    "# models_ncnn = {\n",
    "#     \"YOLOv5n\": \"./convert/model/yolov5/yolo5_ncnn_model\",\n",
    "#     \"YOLOv8n\": \"./convert/model/yolov8/yolo8_ncnn_model\",\n",
    "#     \"YOLO11n\": \"./convert/model/yolov11/yolo11_ncnn_model\",\n",
    "#     \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus_ncnn_model\",\n",
    "# }\n",
    "\n",
    "results = []\n",
    "\n",
    "# %%\n",
    "# --- Benchmark PyTorch ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¥ PYTORCH BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_path in models_pt.items():\n",
    "    try:\n",
    "        result = benchmark_pytorch_inference(\n",
    "            model_path=model_path,\n",
    "            data_yaml=data_yaml,\n",
    "            model_name=model_name,\n",
    "            input_size=(640, 640),\n",
    "            num_warmup=5,\n",
    "            num_samples=100,\n",
    "            device='cpu'\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error benchmarking PyTorch {model_name}: {e}\")\n",
    "\n",
    "# %%\n",
    "# --- Benchmark ONNX ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¥ ONNX BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_path in models_onnx.items():\n",
    "    try:\n",
    "        result = benchmark_onnx_inference(\n",
    "            onnx_path=model_path,\n",
    "            data_yaml=data_yaml,\n",
    "            model_name=model_name,\n",
    "            input_size=(640, 640),\n",
    "            num_warmup=5,\n",
    "            num_samples=100,\n",
    "            device_provider=\"CPUExecutionProvider\"\n",
    "        )\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error benchmarking ONNX {model_name}: {e}\")\n",
    "# # --- Benchmark OpenVINO ---\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"ğŸ”¥ OPENVINO BENCHMARK\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# for model_name, model_path in models_openvino.items():\n",
    "#     try:\n",
    "#         result = benchmark_openvino_inference(\n",
    "#             model_path=model_path,\n",
    "#             data_yaml=data_yaml,\n",
    "#             model_name=model_name,\n",
    "#             input_size=(640, 640),\n",
    "#             num_warmup=5,\n",
    "#             num_samples=100,\n",
    "#             device=\"CPU\"\n",
    "#         )\n",
    "#         if result:\n",
    "#             results.append(result)\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ Error benchmarking OpenVINO {model_name}: {e}\")\n",
    "\n",
    "# # %%\n",
    "# # --- Benchmark NCNN ---\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"ğŸ”¥ NCNN BENCHMARK\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# for model_name, model_dir in models_ncnn.items():\n",
    "#     try:\n",
    "#         param_path = os.path.join(model_dir, \"model.ncnn.param\")\n",
    "#         bin_path = os.path.join(model_dir, \"model.ncnn.bin\")\n",
    "        \n",
    "#         if not (os.path.exists(param_path) and os.path.exists(bin_path)):\n",
    "#             print(f\"âš ï¸  Missing NCNN model files for {model_name}, skipping.\")\n",
    "#             continue\n",
    "        \n",
    "#         result = benchmark_ncnn_inference(\n",
    "#             param_path=param_path,\n",
    "#             bin_path=bin_path,\n",
    "#             data_yaml=data_yaml,\n",
    "#             model_name=model_name,\n",
    "#             input_size=(640, 640),\n",
    "#             num_warmup=5,\n",
    "#             num_samples=100,\n",
    "#             use_gpu=False,\n",
    "#             num_threads=4\n",
    "#         )\n",
    "#         if result:\n",
    "#             results.append(result)\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ Error benchmarking NCNN {model_name}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… BENCHMARK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "save_path = \"/home/pi5/TrafficSign/TT100K/Eval/FPS/detect_eval_results_fps_v5_8_11_custom.csv\"\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"\\nğŸ’¾ Saved results to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d184b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ”¥ OPENVINO BENCHMARK\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Benchmarking OpenVINO: yolo5.xml\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: CPU\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warming up for 5 runs...\n",
      "\n",
      "â±ï¸  Running timed inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.91 ms\n",
      "   âš™ï¸  Inference : 65.39 ms\n",
      "   ğŸ“¦ Postprocess: 0.44 ms\n",
      "   â±ï¸  Total: 73.73 ms â†’ 13.56 FPS\n",
      "\n",
      "ğŸš€ Benchmarking OpenVINO: yolo8.xml\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: CPU\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warming up for 5 runs...\n",
      "\n",
      "â±ï¸  Running timed inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.79 ms\n",
      "   âš™ï¸  Inference : 67.16 ms\n",
      "   ğŸ“¦ Postprocess: 0.44 ms\n",
      "   â±ï¸  Total: 75.39 ms â†’ 13.26 FPS\n",
      "\n",
      "ğŸš€ Benchmarking OpenVINO: yolo11.xml\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: CPU\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warming up for 5 runs...\n",
      "\n",
      "â±ï¸  Running timed inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.78 ms\n",
      "   âš™ï¸  Inference : 67.55 ms\n",
      "   ğŸ“¦ Postprocess: 0.43 ms\n",
      "   â±ï¸  Total: 75.76 ms â†’ 13.20 FPS\n",
      "\n",
      "ğŸš€ Benchmarking OpenVINO: yolo_plus.xml\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ–¥ï¸  Device: CPU\n",
      "ğŸ“Š Running 100 samples (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warming up for 5 runs...\n",
      "\n",
      "â±ï¸  Running timed inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 7.83 ms\n",
      "   âš™ï¸  Inference : 56.20 ms\n",
      "   ğŸ“¦ Postprocess: 0.43 ms\n",
      "   â±ï¸  Total: 64.46 ms â†’ 15.51 FPS\n",
      "\n",
      "============================================================\n",
      "ğŸ”¥ NCNN BENCHMARK\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Benchmarking NCNN: model.ncnn\n",
      "ğŸ“¦ Model: ./convert/model/yolo5/yolo5_ncnn_model/model.ncnn.param\n",
      "ğŸ§© Device: CPU (4 threads)\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 8.86 ms\n",
      "   âš™ï¸  Inference : 65.72 ms\n",
      "   ğŸ“¦ Postprocess: 0.51 ms\n",
      "   â±ï¸  Total: 75.09 ms â†’ 13.32 FPS\n",
      "\n",
      "\n",
      "ğŸš€ Benchmarking NCNN: model.ncnn\n",
      "ğŸ“¦ Model: ./convert/model/yolo8/yolo8_ncnn_model/model.ncnn.param\n",
      "ğŸ§© Device: CPU (4 threads)\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 8.72 ms\n",
      "   âš™ï¸  Inference : 65.36 ms\n",
      "   ğŸ“¦ Postprocess: 0.54 ms\n",
      "   â±ï¸  Total: 74.62 ms â†’ 13.40 FPS\n",
      "\n",
      "\n",
      "ğŸš€ Benchmarking NCNN: model.ncnn\n",
      "ğŸ“¦ Model: ./convert/model/yolo11/yolo11_ncnn_model/model.ncnn.param\n",
      "ğŸ§© Device: CPU (4 threads)\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 9.05 ms\n",
      "   âš™ï¸  Inference : 65.64 ms\n",
      "   ğŸ“¦ Postprocess: 0.52 ms\n",
      "   â±ï¸  Total: 75.21 ms â†’ 13.30 FPS\n",
      "\n",
      "\n",
      "ğŸš€ Benchmarking NCNN: model.ncnn\n",
      "ğŸ“¦ Model: ./convert/model/yolo_plus/yolo_plus_ncnn_model/model.ncnn.param\n",
      "ğŸ§© Device: CPU (4 threads)\n",
      "ğŸ“ Input size: (640, 640)\n",
      "ğŸ“Š Running 100 images (after 5 warmup)\n",
      "\n",
      "ğŸ”¥ Warmup (5 runs)...\n",
      "\n",
      "â±ï¸  Running inference on 100 test images...\n",
      "\n",
      "ğŸ“Š Average Timing (over 100 images):\n",
      "   ğŸ§© Preprocess: 8.80 ms\n",
      "   âš™ï¸  Inference : 50.62 ms\n",
      "   ğŸ“¦ Postprocess: 0.51 ms\n",
      "   â±ï¸  Total: 59.93 ms â†’ 16.69 FPS\n",
      "\n",
      "\n",
      "============================================================\n",
      "âœ… BENCHMARK SUMMARY\n",
      "============================================================\n",
      "      Model         Backend  Avg Preprocess (ms)  Avg Inference (ms)  Avg Postprocess (ms)  Total (ms)       FPS\n",
      "     YOLO5n  OpenVINO (CPU)             7.906253           65.385101              0.438740   73.730094 13.562983\n",
      "     YOLO8n  OpenVINO (CPU)             7.790177           67.162576              0.441494   75.394247 13.263612\n",
      "    YOLO11n  OpenVINO (CPU)             7.777841           67.550220              0.432608   75.760670 13.199461\n",
      "yolo_custom  OpenVINO (CPU)             7.829192           56.199510              0.433137   64.461839 15.513054\n",
      "     YOLO5n NCNN (CPU (4t))             8.860471           65.718722              0.512571   75.091765 13.317040\n",
      "     YOLO8n NCNN (CPU (4t))             8.722947           65.360880              0.537379   74.621205 13.401016\n",
      "    YOLO11n NCNN (CPU (4t))             9.052899           65.635934              0.524442   75.213275 13.295525\n",
      "yolo_custom NCNN (CPU (4t))             8.804078           50.617859              0.506504   59.928441 16.686568\n",
      "\n",
      "ğŸ’¾ Saved results to: /home/pi5/TrafficSign/TT100K/Eval/FPS/detect_eval_results_fps_v5_8_11_custom_part2.csv\n"
     ]
    }
   ],
   "source": [
    "models_openvino = {\n",
    "    \"YOLO5n\": \"./convert/model/yolo5/yolo5_openvino_model/yolo5.xml\",\n",
    "    \"YOLO8n\": \"./convert/model/yolo8/yolo8_openvino_model/yolo8.xml\",\n",
    "    \"YOLO11n\": \"./convert/model/yolo11/yolo11_openvino_model/yolo11.xml\",\n",
    "    \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus_openvino_model/yolo_plus.xml\",\n",
    "}\n",
    "\n",
    "models_ncnn = {\n",
    "    \"YOLO5n\": \"./convert/model/yolo5/yolo5_ncnn_model\",\n",
    "    \"YOLO8n\": \"./convert/model/yolo8/yolo8_ncnn_model\",\n",
    "    \"YOLO11n\": \"./convert/model/yolo11/yolo11_ncnn_model\",\n",
    "    \"yolo_custom\": \"./convert/model/yolo_plus/yolo_plus_ncnn_model\",\n",
    "}\n",
    "\n",
    "results = []\n",
    "# --- Benchmark OpenVINO ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¥ OPENVINO BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_path in models_openvino.items():\n",
    "    try:\n",
    "        result = benchmark_openvino_inference(\n",
    "            model_path=model_path,\n",
    "            data_yaml=data_yaml,\n",
    "            model_name=model_name,\n",
    "            input_size=(640, 640),\n",
    "            num_warmup=5,\n",
    "            num_samples=100,\n",
    "            device=\"CPU\"\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error benchmarking OpenVINO {model_name}: {e}\")\n",
    "\n",
    "# %%\n",
    "# --- Benchmark NCNN ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¥ NCNN BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model_dir in models_ncnn.items():\n",
    "    try:\n",
    "        param_path = os.path.join(model_dir, \"model.ncnn.param\")\n",
    "        bin_path = os.path.join(model_dir, \"model.ncnn.bin\")\n",
    "        \n",
    "        if not (os.path.exists(param_path) and os.path.exists(bin_path)):\n",
    "            print(f\"âš ï¸  Missing NCNN model files for {model_name}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        result = benchmark_ncnn_inference(\n",
    "            param_path=param_path,\n",
    "            bin_path=bin_path,\n",
    "            data_yaml=data_yaml,\n",
    "            model_name=model_name,\n",
    "            input_size=(640, 640),\n",
    "            num_warmup=5,\n",
    "            num_samples=100,\n",
    "            use_gpu=False,\n",
    "            num_threads=4\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error benchmarking NCNN {model_name}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… BENCHMARK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "save_path = \"/home/pi5/TrafficSign/TT100K/Eval/FPS/detect_eval_results_fps_v5_8_11_custom_part2.csv\"\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"\\nğŸ’¾ Saved results to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
